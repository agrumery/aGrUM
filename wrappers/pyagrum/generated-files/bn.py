# This file was automatically generated by SWIG (https://www.swig.org).
# Version 4.4.0
#
# Do not make changes to this file unless you know what you are doing - modify
# the SWIG interface file instead.

"""Bayesian networks module"""

from sys import version_info as _swig_python_version_info
# ## added by passForType (pyAgrum)
from typing import List,Set,Dict,Tuple
# ## recursive import for typehints annotation
import pyagrum
# ## end of added by passForType (pyAgrum)

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _bn
else:
    import _bn

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "this":
            set(self, name, value)
        elif name == "thisown":
            self.this.own(value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import weakref

class SwigPyIterator(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _bn.delete_SwigPyIterator

    def value(self) -> object:
        return _bn.SwigPyIterator_value(self)

    def incr(self, n: int=1) -> "swig::SwigPyIterator *":
        return _bn.SwigPyIterator_incr(self, n)

    def decr(self, n: int=1) -> "swig::SwigPyIterator *":
        return _bn.SwigPyIterator_decr(self, n)

    def distance(self, x: "SwigPyIterator") -> "ptrdiff_t":
        return _bn.SwigPyIterator_distance(self, x)

    def equal(self, x: "SwigPyIterator") -> bool:
        return _bn.SwigPyIterator_equal(self, x)

    def copy(self) -> "swig::SwigPyIterator *":
        return _bn.SwigPyIterator_copy(self)

    def next(self) -> object:
        return _bn.SwigPyIterator_next(self)

    def __next__(self) -> object:
        return _bn.SwigPyIterator___next__(self)

    def previous(self) -> object:
        return _bn.SwigPyIterator_previous(self)

    def advance(self, n: "ptrdiff_t") -> "swig::SwigPyIterator *":
        return _bn.SwigPyIterator_advance(self, n)

    def __eq__(self, x: "SwigPyIterator") -> bool:
        return _bn.SwigPyIterator___eq__(self, x)

    def __ne__(self, x: "SwigPyIterator") -> bool:
        return _bn.SwigPyIterator___ne__(self, x)

    def __iadd__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator &":
        return _bn.SwigPyIterator___iadd__(self, n)

    def __isub__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator &":
        return _bn.SwigPyIterator___isub__(self, n)

    def __add__(self, n: "ptrdiff_t") -> "swig::SwigPyIterator *":
        return _bn.SwigPyIterator___add__(self, n)

    def __sub__(self, *args) -> "ptrdiff_t":
        return _bn.SwigPyIterator___sub__(self, *args)
    def __iter__(self):
        return self

# Register SwigPyIterator in _bn:
_bn.SwigPyIterator_swigregister(SwigPyIterator)
import pyagrum.base
class PythonBNListener(object):
    r"""

    Listener for Bayesian Network's modifications. This listener is notified when the structure of the BN is changed.

    PythonBNListener(bn:pyagrum.BayesNet,vnm:pyagrum.VariableNodeMap) -> PythonBNListener
        default constructor

    Note
    ----
        This class est mainly automatically instantiated using the method pyagrum.BayesNet.addStructureListener.

    Parameters
    ----------
    bn : BaysNet
        The bayes net to listen to
    vnm : VarNodeMap
        A translation unit between id of node and name of variable (usually : bn.variableNodeMap()).

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "pyagrum.BayesNet", vnm: "pyagrum.VariableNodeMap"):
        r"""

        Listener for Bayesian Network's modifications. This listener is notified when the structure of the BN is changed.

        PythonBNListener(bn:pyagrum.BayesNet,vnm:pyagrum.VariableNodeMap) -> PythonBNListener
            default constructor

        Note
        ----
            This class est mainly automatically instantiated using the method pyagrum.BayesNet.addStructureListener.

        Parameters
        ----------
        bn : BaysNet
            The bayes net to listen to
        vnm : VarNodeMap
            A translation unit between id of node and name of variable (usually : bn.variableNodeMap()).

        """
        _bn.PythonBNListener_swiginit(self, _bn.new_PythonBNListener(bn, vnm))
    __swig_destroy__ = _bn.delete_PythonBNListener

    def whenNodeAdded(self, source: object, id: int) -> None:
        return _bn.PythonBNListener_whenNodeAdded(self, source, id)

    def whenNodeDeleted(self, arg2: object, id: int) -> None:
        return _bn.PythonBNListener_whenNodeDeleted(self, arg2, id)

    def whenArcAdded(self, arg2: object, src: int, dst: int) -> None:
        return _bn.PythonBNListener_whenArcAdded(self, arg2, src, dst)

    def whenArcDeleted(self, arg2: object, src: int, dst: int) -> None:
        return _bn.PythonBNListener_whenArcDeleted(self, arg2, src, dst)

    def setWhenArcAdded(self, pyfunc: object) -> None:
        r"""

        Add the listener in parameter to the list of existing ones for adding an arc.

        Parameters
        ----------
        pyfunc : lambda expression
            a function (i:int,j:int) called when when an arc (i,j) is added

        """
        return _bn.PythonBNListener_setWhenArcAdded(self, pyfunc)

    def setWhenArcDeleted(self, pyfunc: object) -> None:
        r"""

        Add the listener in parameter to the list of existing ones for deleting an arc.

        Parameters
        ----------
        pyfunc : lambda expression
            a function (i:int,j:int) called when when an arc (i,j) is removed

        """
        return _bn.PythonBNListener_setWhenArcDeleted(self, pyfunc)

    def setWhenNodeAdded(self, pyfunc: object) -> None:
        r"""

        Add the listener in parameter to the list of existing ones for adding a node.

        Parameters
        ----------
        pyfunc : lambda expression
            a function (i:int,s:str) called when a node of id i and name s is added.

        """
        return _bn.PythonBNListener_setWhenNodeAdded(self, pyfunc)

    def setWhenNodeDeleted(self, pyfunc: object) -> None:
        r"""

        Add the listener in parameter to the list of existing ones for deleting an arc.

        Parameters
        ----------
        pyfunc : lambda expression
            a function (i:int) called when a node of id i and name s is removed.

        """
        return _bn.PythonBNListener_setWhenNodeDeleted(self, pyfunc)

# Register PythonBNListener in _bn:
_bn.PythonBNListener_swigregister(PythonBNListener)
class PythonLoadListener(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def whenLoading(self, buffer: object, percent: int) -> None:
        return _bn.PythonLoadListener_whenLoading(self, buffer, percent)

    def setPythonListener(self, l: object) -> bool:
        r"""



        """
        return _bn.PythonLoadListener_setPythonListener(self, l)

    def __init__(self):
        _bn.PythonLoadListener_swiginit(self, _bn.new_PythonLoadListener())
    __swig_destroy__ = _bn.delete_PythonLoadListener

# Register PythonLoadListener in _bn:
_bn.PythonLoadListener_swigregister(PythonLoadListener)

def _fillLoadListeners_(py_listener: List["pyagrum.PythonLoadListener"], l: object) -> int:
    return _bn._fillLoadListeners_(py_listener, l)
class PythonApproximationListener(object):
    r"""

    Parameters
    ----------
    algo : IApproximationSchemeConfiguration
    	an approxmation scheme

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, algo: "IApproximationSchemeConfiguration"):
        r"""

        Parameters
        ----------
        algo : IApproximationSchemeConfiguration
        	an approxmation scheme

        """
        _bn.PythonApproximationListener_swiginit(self, _bn.new_PythonApproximationListener(algo))
    __swig_destroy__ = _bn.delete_PythonApproximationListener

    def whenProgress(self, src: object, step: int, error: float, duration: float) -> None:
        return _bn.PythonApproximationListener_whenProgress(self, src, step, error, duration)

    def whenStop(self, src: object, message: str) -> None:
        return _bn.PythonApproximationListener_whenStop(self, src, message)

    def setWhenProgress(self, pyfunc: object) -> None:
        r"""

        Parameters
        ----------
        pyfunc
        	the function to execute

        """
        return _bn.PythonApproximationListener_setWhenProgress(self, pyfunc)

    def setWhenStop(self, pyfunc: object) -> None:
        r"""

        Parameters
        ----------
        pyfunc
        	the function to execute

        """
        return _bn.PythonApproximationListener_setWhenStop(self, pyfunc)

# Register PythonApproximationListener in _bn:
_bn.PythonApproximationListener_swigregister(PythonApproximationListener)
class PythonDatabaseGeneratorListener(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, notif: "BNDatabaseGenerator"):
        _bn.PythonDatabaseGeneratorListener_swiginit(self, _bn.new_PythonDatabaseGeneratorListener(notif))
    __swig_destroy__ = _bn.delete_PythonDatabaseGeneratorListener

    def whenProgress(self, src: object, step: int, duration: float) -> None:
        return _bn.PythonDatabaseGeneratorListener_whenProgress(self, src, step, duration)

    def whenStop(self, src: object, message: str) -> None:
        return _bn.PythonDatabaseGeneratorListener_whenStop(self, src, message)

    def setWhenProgress(self, pyfunc: object) -> None:
        return _bn.PythonDatabaseGeneratorListener_setWhenProgress(self, pyfunc)

    def setWhenStop(self, pyfunc: object) -> None:
        return _bn.PythonDatabaseGeneratorListener_setWhenStop(self, pyfunc)

# Register PythonDatabaseGeneratorListener in _bn:
_bn.PythonDatabaseGeneratorListener_swigregister(PythonDatabaseGeneratorListener)
class BNGenerator(object):
    r"""

    BNGenerator is used to easily generate Bayesian networks.

    BNGenerator() -> BNGenerator
        default constructor

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def generate(self, n_nodes: int=10, n_arcs: int=15, n_modmax: int=4) -> "pyagrum.BayesNet":
        r"""

        Generate a new Bayesian network

        Parameters
        ----------
        n_nodes : int
        	the number of nodes (default=10)
        n_arcs : int
        	the number of arcs (default=15)
        n_nodmax : int
        	the max number of modalities for a node (default=4)

        Returns
        -------
        pyagrum.BayesNet
        	the generated Bayesian network

        Raises
        ------
          pyagrum.OperationNotAllowed
        	If n_modmax < 2
          pyagrum.OperationNotAllowed
        	If n_arcs is incompatible with n_nodes (not enough arcs)

        """
        return _bn.BNGenerator_generate(self, n_nodes, n_arcs, n_modmax)

    def __init__(self):
        r"""

        BNGenerator is used to easily generate Bayesian networks.

        BNGenerator() -> BNGenerator
            default constructor

        """
        _bn.BNGenerator_swiginit(self, _bn.new_BNGenerator())
    __swig_destroy__ = _bn.delete_BNGenerator

# Register BNGenerator in _bn:
_bn.BNGenerator_swigregister(BNGenerator)
class InformationTheory(object):
    r"""

    This class gathers information theory concepts for subsets named X,Y and Z computed with only one (optimized) inference.


    **it=pyagrum.InformationTheory(ie,X,Y,Z)**

    Parameters
    ----------
        ie : InferenceEngine
          the inference algorithme to use (for instance, `pyagrum.LazyPropagation`)
        X : int or str or iterable[int or str]
          a first nodeset
        Y  : int or str or iterable[int or str]
          a second nodeset
        Z :  : int or str or iterable[int or str] (optional)
          a third (an optional) nodeset

    Example
    -------

          .. code:: python

              import pyagrum as gum
              bn=pyagrum.fastBN('A->B<-C<-D->E<-F->G->A')
              ie=pyagrum.LazyPropagation(bn)
              it=pyagrum.InformationTheory(ie,'A',['B','G'],['C'])
              print(f'Entropy(A)={it.entropyX()}'')
              print(f'MutualInformation(A;B,G)={it.mutualInformationXY()}')
              print(f'MutualInformation(A;B,G| C)={it.mutualInformationXYgivenZ()}')
              print(f'VariationOfInformation(A;B,G)={it.variationOfInformationXY()}')

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        r"""

        This class gathers information theory concepts for subsets named X,Y and Z computed with only one (optimized) inference.


        **it=pyagrum.InformationTheory(ie,X,Y,Z)**

        Parameters
        ----------
            ie : InferenceEngine
              the inference algorithme to use (for instance, `pyagrum.LazyPropagation`)
            X : int or str or iterable[int or str]
              a first nodeset
            Y  : int or str or iterable[int or str]
              a second nodeset
            Z :  : int or str or iterable[int or str] (optional)
              a third (an optional) nodeset

        Example
        -------

              .. code:: python

                  import pyagrum as gum
                  bn=pyagrum.fastBN('A->B<-C<-D->E<-F->G->A')
                  ie=pyagrum.LazyPropagation(bn)
                  it=pyagrum.InformationTheory(ie,'A',['B','G'],['C'])
                  print(f'Entropy(A)={it.entropyX()}'')
                  print(f'MutualInformation(A;B,G)={it.mutualInformationXY()}')
                  print(f'MutualInformation(A;B,G| C)={it.mutualInformationXYgivenZ()}')
                  print(f'VariationOfInformation(A;B,G)={it.variationOfInformationXY()}')

        """
        _bn.InformationTheory_swiginit(self, _bn.new_InformationTheory(*args))

    def entropyXY(self) -> float:
        r"""

        Returns
        -------
          float
            The entropy of nodeset, union of X and Y.

        """
        return _bn.InformationTheory_entropyXY(self)

    def entropyX(self) -> float:
        r"""

        Returns
        -------
        float
          The entropy of nodeset X.

        """
        return _bn.InformationTheory_entropyX(self)

    def entropyY(self) -> float:
        r"""

        Returns
        -------
          float
            The entropy of nodeset X.

        """
        return _bn.InformationTheory_entropyY(self)

    def entropyXgivenY(self) -> float:
        r"""

        Returns
        -------
          float
            The conditional entropy of nodeset X conditionned by nodeset Y

        """
        return _bn.InformationTheory_entropyXgivenY(self)

    def entropyYgivenX(self) -> float:
        r"""

        Returns
        -------
          float
            The conditional entropy of nodeset Y conditionned by nodeset X

        """
        return _bn.InformationTheory_entropyYgivenX(self)

    def mutualInformationXY(self) -> float:
        return _bn.InformationTheory_mutualInformationXY(self)

    def variationOfInformationXY(self) -> float:
        r"""

        Returns
        -------
          float
            The variation of information between nodeset X and nodeset Y

        """
        return _bn.InformationTheory_variationOfInformationXY(self)

    def entropyXYgivenZ(self) -> float:
        return _bn.InformationTheory_entropyXYgivenZ(self)

    def mutualInformationXYgivenZ(self) -> float:
        r"""

        Returns
        -------
          float
            The conditional mutual information between nodeset X and nodeset Y conditionned by nodeset Z

        """
        return _bn.InformationTheory_mutualInformationXYgivenZ(self)
    __swig_destroy__ = _bn.delete_InformationTheory

# Register InformationTheory in _bn:
_bn.InformationTheory_swigregister(InformationTheory)
class PRMexplorer(object):
    r"""

    PRMexplorer helps navigate through probabilistic relational models.

    PRMexplorer() -> PRMexplorer
        default constructor

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self):
        r"""

        PRMexplorer helps navigate through probabilistic relational models.

        PRMexplorer() -> PRMexplorer
            default constructor

        """
        _bn.PRMexplorer_swiginit(self, _bn.new_PRMexplorer())
    __swig_destroy__ = _bn.delete_PRMexplorer

    def load(self, *args) -> None:
        r"""

        Load a PRM into the explorer.

        Parameters
        ----------
        filename : str
        	the name of the o3prm file
        classpath : str
        	the classpath of the PRM

        Raises
        ------
        pyagrum.FatalError
        	If file not found

        """
        return _bn.PRMexplorer_load(self, *args)

    def isType(self, name: str) -> object:
        r"""

        Parameters
        ----------
        name : str
        	an element name

        Returns
        -------
        bool
        	True if the parameter correspond to a type in the PRM

        """
        return _bn.PRMexplorer_isType(self, name)

    def isClass(self, name: str) -> object:
        r"""

        Parameters
        ----------
        name : str
        	an element name

        Returns
        -------
        bool
        	True if the parameter correspond to a class in the PRM

        """
        return _bn.PRMexplorer_isClass(self, name)

    def isInterface(self, name: str) -> object:
        r"""

        Parameters
        ----------
        name : str
        	an element name

        Returns
        -------
        bool
        	True if the parameter correspond to an interface in the PRM

        """
        return _bn.PRMexplorer_isInterface(self, name)

    def classes(self) -> object:
        r"""

        Returns
        -------
        list
        	the list of classes

        """
        return _bn.PRMexplorer_classes(self)

    def classAttributes(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of attributes

        Raises
        ------
          pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_classAttributes(self, class_name)

    def isAttribute(self, class_name: str, att_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name
        att_name : str
        	the name of the attribute to be tested

        Returns
        -------
        bool
        	True if att_name is an attribute of class_name

        Raises
        ------
        pyagrum.IndexError
        	If the class is not in the PRM
        pyagrum.IndexError
        	If att_name is not an element of class_name

        """
        return _bn.PRMexplorer_isAttribute(self, class_name, att_name)

    def classReferences(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of references

        Raises
        ------
        pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_classReferences(self, class_name)

    def classParameters(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of parameters

        Raises
        ------
          pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_classParameters(self, class_name)

    def classImplements(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of interfaces implemented by the class

        """
        return _bn.PRMexplorer_classImplements(self, class_name)
    aggType = property(_bn.PRMexplorer_aggType_get, _bn.PRMexplorer_aggType_set, doc=r"""

    min/max/count/exists/forall/or/and/amplitude/median

    """)

    def classAggregates(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of aggregates in the class

        Raises
        ------
          pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_classAggregates(self, class_name)

    def classSlotChains(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of class slot chains

        Raises
        ------
        pyagrum.IndexError
        	if the class is not in the PRM

        """
        return _bn.PRMexplorer_classSlotChains(self, class_name)

    def classDag(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        tuple
        	a description of the DAG

        Raises
        ------
          pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_classDag(self, class_name)

    def getalltheSystems(self) -> object:
        r"""

        Returns
        -------
        list
        	the list of all the systems and their components

        """
        return _bn.PRMexplorer_getalltheSystems(self)

    def getSuperClass(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        str
        	the class extended by class_name

        Raises
        ------
        pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_getSuperClass(self, class_name)

    def getDirectSubClass(self, class_name: str) -> object:
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        Returns
        -------
        list
        	the list of direct subclasses

        Raises
        ------
        pyagrum.IndexError
        	If the class is not in the PRM

        """
        return _bn.PRMexplorer_getDirectSubClass(self, class_name)

    def cpf(self, class_name: str, attribute: str) -> "pyagrum.Tensor":
        r"""

        Parameters
        ----------
        class_name : str
        	a class name

        attribute : str
        	an attribute

        Returns
        -------
        pyagrum.Tensor
        	the tensor of the attribute

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the class element doesn't have any pyagrum.Tensor (like a pyagrum.PRMReferenceSlot).
        pyagrum.IndexError
        	If the class is not in the PRM
        pyagrum.IndexError
        	If the attribute in parameters does not exist

        """
        return _bn.PRMexplorer_cpf(self, class_name, attribute)

    def types(self) -> object:
        r"""

        Returns
        -------
        list
        	the list of the custom types in the PRM

        """
        return _bn.PRMexplorer_types(self)

    def getSuperType(self, type_name: str) -> object:
        r"""

        Parameters
        ----------
        type_name : str
        	a type name

        Returns
        -------
        str
        	the type extended by type_name

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_getSuperType(self, type_name)

    def getDirectSubTypes(self, type_name: str) -> object:
        r"""

        Parameters
        ----------
        type_name : str
        	a type name

        Returns
        -------
        list
        	the list of direct subtypes

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_getDirectSubTypes(self, type_name)

    def getLabels(self, type_name: str) -> object:
        r"""

        Parameters
        ----------
        type_name : str
        	a type name

        Returns
        -------
        list
        	the list of type labels

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_getLabels(self, type_name)

    def getLabelMap(self, type_name: str) -> object:
        r"""

        Parameters
        ----------
        type_name : str
        	a type name

        Returns
        -------
        dict
        	a dict containing pairs of label and their values

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_getLabelMap(self, type_name)

    def interfaces(self) -> object:
        r"""

        Returns
        -------
        list
        	the list of interfaces in the PRM

        """
        return _bn.PRMexplorer_interfaces(self)

    def interAttributes(self, interface_name: str, allAttributes: bool=False) -> object:
        r"""

        Parameters
        ----------
        interface_name : str
        	an interface

        allAttributes : bool
        	True if supertypes of a custom type should be indicated

        Returns
        -------
        list
        	the list of (<type>,<attribute_name>) for the given interface

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_interAttributes(self, interface_name, allAttributes)

    def interReferences(self, interface_name: str) -> object:
        r"""

        Parameters
        ----------
        interface_name : str
        	an interface

        Returns
        -------
        list
        	the list of (<reference_type>,<reference_name>,<True if the reference is an array>) for the given interface

        Raises
        ------
        pyagrum.IndexError
        	If the type is not in the PRM

        """
        return _bn.PRMexplorer_interReferences(self, interface_name)

    def getSuperInterface(self, interface_name: str) -> object:
        r"""

        Parameters
        ----------
        interface_name : str
        	an interface name

        Returns
        -------
        str
        	the interace extended by interface_name

        Raises
        ------
        pyagrum.IndexError
        	If the interface is not in the PRM

        """
        return _bn.PRMexplorer_getSuperInterface(self, interface_name)

    def getDirectSubInterfaces(self, interface_name: str) -> object:
        r"""

        Parameters
        ----------
        interface_name : str
        	an interface name

        Returns
        -------
        list
        	the list of direct subinterfaces

        Raises
        ------
        pyagrum.IndexError
        	If the interface is not in the PRM

        """
        return _bn.PRMexplorer_getDirectSubInterfaces(self, interface_name)

    def getImplementations(self, interface_name: str) -> object:
        r"""

        Parameters
        ----------
        interface_name : str
        	an interface name

        Returns
        -------
        str
        	the list of classes implementing the interface

        Raises
        ------
        pyagrum.IndexError
        	If the interface is not in the PRM

        """
        return _bn.PRMexplorer_getImplementations(self, interface_name)

# Register PRMexplorer in _bn:
_bn.PRMexplorer_swigregister(PRMexplorer)
class EssentialGraph(object):
    r"""

    Class building the essential graph from a BN.

    Essential graph is a mixed graph (Chain Graph) that represents the class of markov equivalent Bayesian networks (with the same independency model).

    EssentialGraph(m) -> EssentialGraph
        Parameters:
          - **m** (*pyagrum.DAGmodel*) -- a DAGmodel

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.EssentialGraph_swiginit(self, _bn.new_EssentialGraph(*args))
    __swig_destroy__ = _bn.delete_EssentialGraph

    def pdag(self) -> "pyagrum.PDAG":
        r"""

        Returns
        -------
        pyagrum.PDAG
        	the PDAG (Partially Directed Graph)

        """
        return _bn.EssentialGraph_pdag(self)

    def toDot(self) -> str:
        r"""

        Returns
        -------
        str
            a friendly display of the graph in DOT format

        """
        return _bn.EssentialGraph_toDot(self)

    def sizeArcs(self) -> int:
        r"""

        Returns
        -------
        int
            the number of arcs in the graph

        """
        return _bn.EssentialGraph_sizeArcs(self)

    def sizeEdges(self) -> int:
        r"""

        Returns
        -------
        int
            the number of edges in the graph

        """
        return _bn.EssentialGraph_sizeEdges(self)

    def sizeNodes(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of nodes in the graph

        """
        return _bn.EssentialGraph_sizeNodes(self)

    def size(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of nodes in the graph

        """
        return _bn.EssentialGraph_size(self)

    def skeleton(self) -> "pyagrum.UndiGraph":
        return _bn.EssentialGraph_skeleton(self)

    def idFromName(self, name: str) -> int:
        r"""

        Parameters
        ----------
        name : str
          the name of the variable in the model

        Returns
        -------
        int
          the nodeId from the name of the variable in the model

        """
        return _bn.EssentialGraph_idFromName(self, name)

    def nameFromId(self, node: int) -> str:
        r"""

        Parameters
        ----------
        node : int
          the nodeId of the variable in the model

        Returns
        -------
        str
          the name of the variable in the model from the nodeId

        """
        return _bn.EssentialGraph_nameFromId(self, node)

    def nodes(self) -> object:
        return _bn.EssentialGraph_nodes(self)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


    def arcs(self) -> object:
        r"""

        Returns
        -------
        list
        	The lisf of arcs in the EssentialGraph

        """
        return _bn.EssentialGraph_arcs(self)

    def parents(self, id: int) -> object:
        r"""

        Parameters
        ----------
        id :
        	The id of the child node

        Returns
        -------
        Set
            the set of the parents ids.

        """
        return _bn.EssentialGraph_parents(self, id)

    def children(self, id: int) -> object:
        r"""

        Parameters
        ----------
        id : int
          the id of the parent

        Returns
        -------
        Set
        	the set of all the children

        """
        return _bn.EssentialGraph_children(self, id)

    def edges(self) -> object:
        r"""

        Returns
        -------
        List
          the list of the edges

        """
        return _bn.EssentialGraph_edges(self)

    def neighbours(self, id: int) -> object:
        r"""

        Parameters
        ----------
        id : int
            the id of the checked node

        Returns
        -------
        Set
            The set of edges adjacent to the given node

        """
        return _bn.EssentialGraph_neighbours(self, id)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


# Register EssentialGraph in _bn:
_bn.EssentialGraph_swigregister(EssentialGraph)
class MarkovBlanket(object):
    r"""

    Class building the Markov blanket of a node in a graph.

    MarkovBlanket(m,n) -> MarkovBlanket
        Parameters:
            - **m** (*pyagrum.DAGmodel*) -- a DAGmodel
            - **n** (int) -- a node id

    MarkovBlanket(m,name) -> MarkovBlanket
        Parameters:
            - **m** (*pyagrum.DAGmodel*) -- a DAGmodel
            - **name** (*str*) -- a node name

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.MarkovBlanket_swiginit(self, _bn.new_MarkovBlanket(*args))
    __swig_destroy__ = _bn.delete_MarkovBlanket

    def dag(self) -> "pyagrum.DAG":
        r"""

        Returns
        -------
        pyagrum.DAG
          a copy of the DAG

        """
        return _bn.MarkovBlanket_dag(self)

    def toDot(self) -> str:
        r"""

        Returns
        -------
        str
            a friendly display of the graph in DOT format

        """
        return _bn.MarkovBlanket_toDot(self)

    def sizeArcs(self) -> int:
        r"""

        Returns
        -------
        int
            the number of arcs in the graph

        """
        return _bn.MarkovBlanket_sizeArcs(self)

    def sizeNodes(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of nodes in the graph

        """
        return _bn.MarkovBlanket_sizeNodes(self)

    def size(self) -> int:
        r"""

        Returns
        -------
        int
            the number of nodes in the graph

        """
        return _bn.MarkovBlanket_size(self)

    def hasSameStructure(self, other: "pyagrum.DAGmodel") -> bool:
        r"""

        Parameters
        ----------
        pyagrum.DAGmodel
        	a direct acyclic model

        Returns
        -------
        bool
            True if all the named node are the same and all the named arcs are the same

        """
        return _bn.MarkovBlanket_hasSameStructure(self, other)

    def nodes(self) -> object:
        r"""

        Returns
        -------
        set
            the set of ids

        """
        return _bn.MarkovBlanket_nodes(self)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


    def arcs(self) -> object:
        r"""

        Returns
        -------
        List
        	the list of the arcs

        """
        return _bn.MarkovBlanket_arcs(self)

    def parents(self, id: int) -> object:
        r"""

        Parameters
        ----------
        id :
        	The id of the child node

        Returns
        -------
        Set
            the set of the parents ids.

        """
        return _bn.MarkovBlanket_parents(self, id)

    def children(self, id: int) -> object:
        r"""

        Parameters
        ----------
        id : int
          the id of the parent

        Returns
        -------
        Set
        	the set of all the children

        """
        return _bn.MarkovBlanket_children(self, id)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


# Register MarkovBlanket in _bn:
_bn.MarkovBlanket_swigregister(MarkovBlanket)
class StructuralComparator(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self):
        _bn.StructuralComparator_swiginit(self, _bn.new_StructuralComparator())
    __swig_destroy__ = _bn.delete_StructuralComparator

    def compare(self, *args) -> None:
        r"""

        Use to compare the edges/arcs of two structure of the same type and same sizes (either DiGraph, UndiGraph or MixedGraph).

        Could be use to compare a BN and its learned version.

        Parameters
        ----------
        ref :
        	the structure of reference
        test :
        	the structure we want to test

        """
        return _bn.StructuralComparator_compare(self, *args)

    def precision_skeleton(self) -> float:
        r"""

        Rate of true postive over labelized edges.

        Returns
        -------
        float
        	the precision of the tested graph skeleton

        """
        return _bn.StructuralComparator_precision_skeleton(self)

    def recall_skeleton(self) -> float:
        r"""

        Rate of true postive over labelized edges.

        Returns
        -------
        float
        	the recall of the tested graph skeleton

        """
        return _bn.StructuralComparator_recall_skeleton(self)

    def f_score_skeleton(self) -> float:
        r"""

        Harmonic mean between recall and precision.

        Returns
        -------
        float
        	the tarmonic mean of the tested graph skeleton

        """
        return _bn.StructuralComparator_f_score_skeleton(self)

    def precision(self) -> float:
        r"""

        Rate of true postive over postively labelized arcs/edges.

        Returns
        -------
        float
        	the precision of the tested graph

        """
        return _bn.StructuralComparator_precision(self)

    def recall(self) -> float:
        r"""

        Rate of true postive over labelized arcs/edges.

        Returns
        -------
        float
        	the recall of the tested graph

        """
        return _bn.StructuralComparator_recall(self)

    def f_score(self) -> float:
        r"""

        Harmonic mean between recall and precision.

        Returns
        -------
        float
        	the harmonic mean of the tested graph

        """
        return _bn.StructuralComparator_f_score(self)

# Register StructuralComparator in _bn:
_bn.StructuralComparator_swigregister(StructuralComparator)
FindBarrenNodesType_FIND_NO_BARREN_NODES = _bn.FindBarrenNodesType_FIND_NO_BARREN_NODES
FindBarrenNodesType_FIND_BARREN_NODES = _bn.FindBarrenNodesType_FIND_BARREN_NODES
class IBayesNet(pyagrum.base.DAGmodel):
    r"""

    Abstract class used by BayesNet.

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __swig_destroy__ = _bn.delete_IBayesNet

    def cpt(self, varId: int) -> "pyagrum.Tensor":
        r"""

        Returns the CPT of a variable.

        Parameters
        ----------
        VarId : int
        	A variable's id in the pyagrum.IBayesNet.
        name : str
        	A variable's name in the pyagrum.IBayesNet.

        Returns
        -------
        pyagrum.Tensor
        	The variable's CPT.

        Raises
        ------
        pyagrum.NotFound
        	If no variable's id matches varId.

        """
        return _bn.IBayesNet_cpt(self, varId)

    def variableNodeMap(self) -> "pyagrum.VariableNodeMap":
        r"""

        Returns
        -------
        pyagrum.variableNodeMap
        	the variable node map

        """
        return _bn.IBayesNet_variableNodeMap(self)

    def variable(self, id: int) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        id : int
        	a variable's id
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.IBayesNet_variable(self, id)

    def nodeId(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Parameters
        ----------
        var : pyagrum.DiscreteVariable
        	a variable

        Returns
        -------
        int
        	the id of the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.IBayesNet_nodeId(self, var)

    def idFromName(self, name: str) -> int:
        r"""

        Returns a variable's id given its name in the graph.

        Parameters
        ----------
        name : str
        	The variable's name from which the id is returned.

        Notes
        -----
          A convenient shortcut for `g.variableFromName(name)` is `g[name]`.

        Returns
        -------
        int :
        	The variable's node id.

        Raises
        ------
        pyagrum.NotFound
        	If name does not match a variable in the graph

        """
        return _bn.IBayesNet_idFromName(self, name)

    def variableFromName(self, name: str) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.IBayesNet_variableFromName(self, name)

    def jointProbability(self, i: "pyagrum.Instantiation") -> float:
        r"""

        Parameters
        ----------
        i : pyagrum.instantiation
        	an instantiation of the variables

        Returns
        -------
        float
        	a parameter of the joint probability for the BayesNet

        Warnings
        --------
        a variable not present in the instantiation is assumed to be instantiated to 0

        """
        return _bn.IBayesNet_jointProbability(self, i)

    def log2JointProbability(self, i: "pyagrum.Instantiation") -> float:
        r"""

        Parameters
        ----------
        i : pyagrum.instantiation
        	an instantiation of the variables

        Returns
        -------
        float
        	a parameter of the log joint probability for the BayesNet

        Warnings
        --------
        a variable not present in the instantiation is assumed to be instantiated to 0

        """
        return _bn.IBayesNet_log2JointProbability(self, i)

    def check(self) -> List[str]:
        r"""

        Check if the BayesNet is consistent (variables, CPT, ...)

        Returns
        -------
        List[str]
          list of found issues

        """
        return _bn.IBayesNet_check(self)

    def __eq__(self, _from: "IBayesNet") -> bool:
        return _bn.IBayesNet___eq__(self, _from)

    def __ne__(self, _from: "IBayesNet") -> bool:
        return _bn.IBayesNet___ne__(self, _from)

    def dim(self) -> int:
        r"""

        Returns the dimension (the number of free parameters) in this BayesNet.

        Returns
        -------
        int
        	the dimension of the BayesNet

        """
        return _bn.IBayesNet_dim(self)

    def maxVarDomainSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the biggest domain size among the variables of the BayesNet

        """
        return _bn.IBayesNet_maxVarDomainSize(self)

    def minParam(self) -> float:
        r"""

        Returns
        -------
        float
            the smallest value in the CPTs of the IBayesNet

        """
        return _bn.IBayesNet_minParam(self)

    def maxParam(self) -> float:
        r"""

        Returns
        -------
        float
            the biggest value in the CPTs of the BayesNet

        """
        return _bn.IBayesNet_maxParam(self)

    def minNonZeroParam(self) -> float:
        r"""

        Returns
        -------
        float
            the smallest value (not equal to 0) in the CPTs of the IBayesNet

        """
        return _bn.IBayesNet_minNonZeroParam(self)

    def maxNonOneParam(self) -> float:
        r"""

        Returns
        -------
        float
        	The biggest value (not equal to 1) in the CPTs of the BayesNet

        """
        return _bn.IBayesNet_maxNonOneParam(self)

    def toDot(self) -> str:
        r"""

        Returns
        -------
        str
            a friendly display of the graph in DOT format

        """
        return _bn.IBayesNet_toDot(self)

    def evEq(self, name: str, value: float) -> "pyagrum.Tensor":
        return _bn.IBayesNet_evEq(self, name, value)

    def evIn(self, name: str, val1: float, val2: float) -> "pyagrum.Tensor":
        return _bn.IBayesNet_evIn(self, name, val1, val2)

    def evLt(self, name: str, value: float) -> "pyagrum.Tensor":
        return _bn.IBayesNet_evLt(self, name, value)

    def evGt(self, name: str, value: float) -> "pyagrum.Tensor":
        return _bn.IBayesNet_evGt(self, name, value)

    def memoryFootprint(self) -> int:
        r"""

        get the size (in byte) of the (main footprint) of the BayesNet

        Returns
        -------
        int
          the size in byte of the representation (of the parameters) of the BayesNet

        """
        return _bn.IBayesNet_memoryFootprint(self)

    def ids(self, names: List[str]) -> object:
        r"""

        List of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        List[int]
        	The ids for the list of names of the graph variables

        """
        return _bn.IBayesNet_ids(self, names)

    def nodeset(self, names: List[str]) -> object:
        r"""

        Set of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        Set[int]
        	The set of ids for the list of names of the graph variables

        """
        return _bn.IBayesNet_nodeset(self, names)

    def minimalCondSet(self, *args) -> object:
        r"""

        Returns, given one or many targets and a list of variables, the minimal set of those needed to calculate the target/targets.

        Parameters
        ----------
        target : int
        	The id of the target
        targets : List[int]
        	The ids of the targets
        list : List[int]
        	The list of available variables

        Returns
        -------
        Set[int]
        	The minimal set of variables

        """
        return _bn.IBayesNet_minimalCondSet(self, *args)

    def isIndependent(self, *args) -> bool:
        r"""

        check if nodes X and nodes Y are independent given nodes Z

        Parameters
        ----------
        X : str|intList[str|int]
              a list of of nodeIds or names
        Y : str|intList[str|int]
              a list of of nodeIds or names
        Z : str|intList[str|int]
              a list of of nodeIds or names

        Raises
        ------
        InvalidArgument
          if X and Y share variables

        Returns
        -------
        bool
          True if X and Y are independent given Z in the model

        """
        return _bn.IBayesNet_isIndependent(self, *args)

    def names(self) -> object:
        r"""

        Set of names of variables in the model

        Returns
        -------
        Set[str]
        	The names of the graph variables

        """
        return _bn.IBayesNet_names(self)

    def __iter__(self):
      """
      Iterate over the variables of the model

      Yield
      -----
      Tuple[int,str]
        The index of the variable and its name
      """
      for i in self.nodes():
        yield i,self.variable(i).name()

    def __getitem__(self, key):
      if isinstance(key, int):
        return self.variable(key)
      elif isinstance(key, str):
        return self.variableFromName(key)
      else:
        raise TypeError("key must be an int or a string")


    def nodes(self) -> object:
        r"""

        Returns
        -------
        Set[int]
            the set of ids

        """
        return _bn.IBayesNet_nodes(self)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


    def arcs(self) -> object:
        r"""

        Returns
        -------
        list
        	The lisf of arcs in the IBayesNet

        """
        return _bn.IBayesNet_arcs(self)

    def parents(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id :
        	The id of the child node

        Returns
        -------
        Set
            the set of the parents ids.

        """
        return _bn.IBayesNet_parents(self, norid)

    def children(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id : int
          the id of the parent

        Returns
        -------
        Set
        	the set of all the children

        """
        return _bn.IBayesNet_children(self, norid)

    def family(self, norid: object) -> object:
        r"""

        give the set of parents of a node and the node

        Parameters
        ---------
        norid : str|int
          the node

        Returns
        -------
        Set[int]
          the set of nodeId of the family of the node `norid`

        """
        return _bn.IBayesNet_family(self, norid)

    def descendants(self, norid: object) -> object:
        r"""

        give the set of nodeid of descendants of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the descendants of node `norid`.

        """
        return _bn.IBayesNet_descendants(self, norid)

    def ancestors(self, norid: object) -> object:
        r"""

        give the set of nodeid of ancestors of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the ancestors of node `norid`.

        """
        return _bn.IBayesNet_ancestors(self, norid)

    def moralizedAncestralGraph(self, nodes: object) -> "pyagrum.UndiGraph":
        r"""

        build a UndiGraph by moralizing the Ancestral Graph of a list of nodes

        Parameters
        ----------
        nodes : str|intList[str|int]
          the list of of nodeIds or names

        Warnings
        --------
          pyagrum.UndiGraph only knows NodeId. Hence the moralized ancestral graph does not include the names of the variables.graph

        Returns
        -------
        pyagrum.UndiGraph
          the moralized ancestral graph of the nodes

        """
        return _bn.IBayesNet_moralizedAncestralGraph(self, nodes)

    def __repr__(self) -> str:
        return _bn.IBayesNet___repr__(self)

    def __str__(self) -> str:
        return _bn.IBayesNet___str__(self)

# Register IBayesNet in _bn:
_bn.IBayesNet_swigregister(IBayesNet)
class BayesNet(IBayesNet):
    r"""

    BayesNet represents a Bayesian network.

    BayesNet(name='') -> BayesNet
        Parameters:
          - **name** (*str*) -- the name of the Bayes Net

    BayesNet(source) -> BayesNet
        Parameters:
          - **source** (*pyagrum.BayesNet*) -- the Bayesian network to copy

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    @staticmethod
    def fastPrototype(*args) -> "pyagrum.BayesNet":
        r"""

        Create a Bayesian network with a dot-like syntax which specifies:
            - the structure 'a->b->c;b->d<-e;'.
            - the type of the variables with different syntax:

              - by default, a variable is a pyagrum.RangeVariable using the default domain size ([2])
              - with 'a[10]', the variable is a pyagrum.RangeVariable using 10 as domain size (from 0 to 9)
              - with 'a[3,7]', the variable is a pyagrum.RangeVariable using a domainSize from 3 to 7
              - with 'a[1,3.14,5,6.2]', the variable is a pyagrum.DiscretizedVariable using the given ticks (at least 3 values)
              - with 'a{top|middle|bottom}', the variable is a pyagrum.LabelizedVariable using the given labels.
              - with 'a{-1|5|0|3}', the variable is a pyagrum.IntegerVariable using the sorted given values.
              - with 'a{-0.5|5.01|0|3.1415}', the variable is a pyagrum.NumericalDiscreteVariable using the sorted given values.

        Note
        ----
          - If the dot-like string contains such a specification more than once for a variable, the first specification will be used.
          - the CPTs are randomly generated.
          - see also pyagrum.fastBN.

        Examples
        --------
        >>> import pyagrum as gum
        >>> bn=pyagrum.BayesNet.fastPrototype('A->B[1,3]<-C{yes|No}->D[2,4]<-E[1,2.5,3.9]',6)

        Parameters
        ----------
        dotlike : str
                the string containing the specification
        domainSize : int or str
                the default domain size or the default domain for variables

        Returns
        -------
        pyagrum.BayesNet
                the resulting Bayesian network

        """
        return _bn.BayesNet_fastPrototype(*args)
    __swig_destroy__ = _bn.delete_BayesNet

    def __init__(self, *args):
        _bn.BayesNet_swiginit(self, _bn.new_BayesNet(*args))

    def cpt(self, *args) -> "pyagrum.Tensor":
        r"""

        Returns the CPT of a variable.

        Parameters
        ----------
        VarId :  Union[int,str]
        	a variable's id (int) or name

        Returns
        -------
        pyagrum.Tensor
        	The variable's CPT.

        Raises
        ------
        pyagrum.NotFound
            If no variable's id matches varId.

        """
        return _bn.BayesNet_cpt(self, *args)

    def variableNodeMap(self) -> "pyagrum.VariableNodeMap":
        r"""

        Returns
        -------
        pyagrum.variableNodeMap
        	the variable node map

        """
        return _bn.BayesNet_variableNodeMap(self)

    def add(self, *args) -> int:
        r"""

        Add a variable to the pyagrum.BayesNet.

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable added
        descr : str
        	the description of the variable (following :ref:`fast syntax<Quick specification of (randomly parameterized) graphical models>`)
        nbrmod : int
        	the number of modalities for the new variable
        id : int
        	the variable forced id in the pyagrum.BayesNet

        Returns
        -------
        int
        	the id of the new node

        Raises
        ------
        pyagrum.DuplicateLabel
            If variable.name() or id is already used in this pyagrum.BayesNet.
        pyagrum.NotAllowed
            If nbrmod is less than 2

        """
        return _bn.BayesNet_add(self, *args)

    def clear(self) -> None:
        r"""

        Clear the whole BayesNet

        """
        return _bn.BayesNet_clear(self)

    def erase(self, *args) -> None:
        r"""

        Remove a variable from the pyagrum.BayesNet.

        Removes the corresponding variable from the pyagrum.BayesNet and from all of it's children pyagrum.Tensor.

        If no variable matches the given id, then nothing is done.

        Parameters
        ----------
        var : Union[int,str,pyagrum.DiscreteVariable]
        	the current name, the id of the variable or a reference to the variable

        """
        return _bn.BayesNet_erase(self, *args)

    def variable(self, *args) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        id : int
        	a variable's id
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNet_variable(self, *args)

    def changeVariableName(self, *args) -> None:
        r"""

        Changes a variable's name in the pyagrum.BayesNet.

        This will change the "pyagrum.DiscreteVariable" names in the pyagrum.BayesNet.

        Parameters
        ----------
        var : Union[int,str]
        	the current name or the id of the variable
        new_name : str
        	the new name of the variable

        Raises
        ------
        pyagrum.DuplicateLabel
            If new_name is already used in this BayesNet.
        pyagrum.NotFound
            If no variable matches id.

        """
        return _bn.BayesNet_changeVariableName(self, *args)

    def changeVariableLabel(self, *args) -> None:
        r"""

        change the label of the variable associated to nodeId to the new value.

        Parameters
        ----------
        var : Union[int,str]
        	the current name or the id of the variable
        old_label : str
        	the new label
        new_label : str
        	the new label

        Raises
        ------
        pyagrum.NotFound
            if id/name is not a variable or if old_label does not exist.

        """
        return _bn.BayesNet_changeVariableLabel(self, *args)

    def nodeId(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Parameters
        ----------
        var : pyagrum.DiscreteVariable
        	a variable

        Returns
        -------
        int
        	the id of the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNet_nodeId(self, var)

    def idFromName(self, name: str) -> int:
        r"""

        Returns a variable's id given its name in the graph.

        Parameters
        ----------
        name : str
        	The variable's name from which the id is returned.

        Notes
        -----
          A convenient shortcut for `g.variableFromName(name)` is `g[name]`.

        Returns
        -------
        int :
        	The variable's node id.

        Raises
        ------
        pyagrum.NotFound
        	If name does not match a variable in the graph

        """
        return _bn.BayesNet_idFromName(self, name)

    def variableFromName(self, name: str) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNet_variableFromName(self, name)

    def addArc(self, *args) -> None:
        r"""

        Add an arc in the BN, and update arc.head's CPT.

        Parameters
        ----------
        head : Union[int,str]
        	a variable's id (int) or name
        head : Union[int,str]
        	a variable's id (int) or name

        Raises
        ------
        pyagrum.InvalidEdge
            If arc.tail and/or arc.head are not in the BN.
        pyagrum.DuplicateElement
            If the arc already exists.

        """
        return _bn.BayesNet_addArc(self, *args)

    def eraseArc(self, *args) -> None:
        r"""

        Removes an arc in the BN, and update head's CTP.

        If (tail, head) doesn't exist, the nothing happens.

        Parameters
        ----------
        arc : pyagrum.Arc when calling eraseArc(arc)
        	The arc to be removed.
        head : Union[int,str]
        	a variable's id (int) or name for the head when calling eraseArc(head,tail)
        tail : Union[int,str]
        	a variable's id (int) or name for the tail when calling eraseArc(head,tail)

        """
        return _bn.BayesNet_eraseArc(self, *args)

    def beginTopologyTransformation(self) -> None:
        r"""

        When inserting/removing arcs, node CPTs change their dimension with a cost in time.
        begin Multiple Change for all CPTs
        These functions delay the CPTs change to be done just once at the end of a sequence of topology modification, begins a sequence of insertions/deletions of arcs without changing the dimensions of the CPTs.

        """
        return _bn.BayesNet_beginTopologyTransformation(self)

    def endTopologyTransformation(self) -> None:
        r"""

        Terminates a sequence of insertions/deletions of arcs by adjusting all CPTs dimensions.
        End Multiple Change for all CPTs.

        Returns
        -------
        pyagrum.BayesNet

        """
        return _bn.BayesNet_endTopologyTransformation(self)

    def reverseArc(self, *args) -> None:
        r"""

        Reverses an arc while preserving the same joint distribution.

        Parameters
        ----------
        tail
        	(int) the id of the tail variable
        head
        	(int) the id of the head variable
        tail
        	(str) the name of the tail variable
        head
        	(str) the name of the head variable
        arc : pyagrum.Arc
        	an arc

        Raises
        ------
        pyagrum.InvalidArc
            If the arc does not exsit or if its reversal would induce a directed cycle.

        """
        return _bn.BayesNet_reverseArc(self, *args)

    def addNoisyOR(self, *args) -> int:
        r"""

        Add a variable, it's associate node and a noisyOR implementation.

        Since it seems that the 'classical' noisyOR is the Compound noisyOR, we keep the addNoisyOR as an alias for addNoisyORCompound.

        (The id of the new variable can be automatically generated.)

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy
        externalWeight : float
        	the added external weight
        id : int
        	The proposed id for the variable.

        Returns
        -------
        int
        	the id of the added variable.

        Raises
        --------
        pyagrum.DuplicateElement
            If id is already used

        """
        return _bn.BayesNet_addNoisyOR(self, *args)

    def addNoisyORNet(self, *args) -> int:
        r"""

        Add a variable, its associate node and a noisyOR implementation.

        Since it seems that the 'classical' noisyOR is the Compound noisyOR, we keep the addNoisyOR as an alias for addNoisyORCompound.

        (The id of the new variable can be automatically generated.)

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy
        externalWeight : float
        	the added external weight
        id : int
        	The proposed id for the variable.

        Returns
        -------
        int
        	the id of the added variable.

        """
        return _bn.BayesNet_addNoisyORNet(self, *args)

    def addNoisyORCompound(self, *args) -> int:
        r"""

        Add a variable, it's associate node and a noisyOR implementation.

        Since it seems that the 'classical' noisyOR is the Compound noisyOR, we keep the addNoisyOR as an alias for addNoisyORCompound.

        (The id of the new variable can be automatically generated.)

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy
        externalWeight : float
        	the added external weight
        id : int
        	The proposed id for the variable.

        Returns
        -------
        int
        	the id of the added variable.

        Raises
        --------
        pyagrum.DuplicateElement
            If id is already used

        """
        return _bn.BayesNet_addNoisyORCompound(self, *args)

    def addNoisyAND(self, *args) -> int:
        r"""

        Add a variable, its associate node and a noisyAND implementation.

        (The id of the new variable can be automatically generated.)

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy
        externalWeight : float
        	the added external weight
        id : int
        	The proposed id for the variable.

        Returns
        -------
        int
        	the id of the added variable.

        Raises
        ------
        pyagrum.DuplicateElement
            If id is already used

        """
        return _bn.BayesNet_addNoisyAND(self, *args)

    def addLogit(self, *args) -> int:
        r"""

        Add a variable, its associate node and a Logit implementation.

        (The id of the new variable can be automatically generated.)

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy
        externalWeight : float
        	the added external weight
        id : int
        	The proposed id for the variable.
        Returns
        -------
        int
        	the id of the added variable.

        Raises
        ------
        pyagrum.DuplicateElement
            If id is already used

        """
        return _bn.BayesNet_addLogit(self, *args)

    def addOR(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Add a variable, it's associate node and an OR implementation.

        The id of the new variable is automatically generated.

        Warnings
        --------
        	If parents are not boolean, all value>1 is True

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy

        Returns
        -------
        int
        	the id of the added variable.

        Raises
        ------
        pyagrum.SizeError
            If variable.domainSize()>2

        """
        return _bn.BayesNet_addOR(self, var)

    def addAND(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Add a variable, it's associate node and an AND implementation.

        The id of the new variable is automatically generated.

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	The variable added by copy.

        Returns
        -------
        int
        	the id of the added variable.

        Raises
        ------
        pyagrum.SizeError
            If variable.domainSize()>2

        """
        return _bn.BayesNet_addAND(self, var)

    def addAMPLITUDE(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addAMPLITUDE(self, var)

    def addCOUNT(self, var: "pyagrum.DiscreteVariable", value: int=1) -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addCOUNT(self, var, value)

    def addEXISTS(self, var: "pyagrum.DiscreteVariable", value: int=1) -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addEXISTS(self, var, value)

    def addFORALL(self, var: "pyagrum.DiscreteVariable", value: int=1) -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added variable.

        """
        return _bn.BayesNet_addFORALL(self, var, value)

    def addMAX(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addMAX(self, var)

    def addMEDIAN(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addMEDIAN(self, var)

    def addMIN(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
        	the variable to be added

        Returns
        -------
        int
        	the id of the added value

        """
        return _bn.BayesNet_addMIN(self, var)

    def addSUM(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Others aggregators

        Parameters
        ----------
        variable : pyagrum.DiscreteVariable
                the variable to be added

        Returns
        -------
        int
                the id of the added value

        """
        return _bn.BayesNet_addSUM(self, var)

    def addWeightedArc(self, *args) -> None:
        r"""

        Add an arc in the BN, and update arc.head's CPT.

        Parameters
        ----------
        head : Union[int,str]
        	a variable's id (int) or name
        tail : Union[int,str]
        	a variable's id (int) or name
        causalWeight : float
        	the added causal weight

        Raises
        ------
        pyagrum.InvalidArc
            If arc.tail and/or arc.head are not in the BN.
        pyagrum.InvalidArc
            If variable in arc.head is not a NoisyOR variable.

        """
        return _bn.BayesNet_addWeightedArc(self, *args)

    def generateCPTs(self) -> None:
        r"""

        Randomly generates CPTs for a given structure.

        """
        return _bn.BayesNet_generateCPTs(self)

    def generateCPT(self, *args) -> None:
        r"""

        Randomly generate CPT for a given node in a given structure.

        Parameters
        ----------
        node : Union[int,str]
        	a variable's id (int) or name

        """
        return _bn.BayesNet_generateCPT(self, *args)

    def changeTensor(self, *args) -> None:
        r"""

        change the CPT associated to nodeId to newPot delete the old CPT associated to nodeId.

        Parameters
        ----------
        var : Union[int,str]
        	the current name or the id of the variable
        newPot : pyagrum.Tensor
        	the new tensor

        Raises
        ------
        pyagrum.NotAllowed
            If newPot has not the same signature as __probaMap[NodeId]

        """
        return _bn.BayesNet_changeTensor(self, *args)

    def dag(self) -> "pyagrum.DAG":
        r"""

        Returns
        -------
        pyagrum.DAG
        	a constant reference to the dag of this BayesNet.

        """
        val = _bn.BayesNet_dag(self)

        from pyagrum.base import DAG
        val = DAG(val) # copying the DAG


        return val


    def size(self) -> int:
        r"""

        Returns
        -------
        int
            the number of nodes in the graph

        """
        return _bn.BayesNet_size(self)

    def log10DomainSize(self) -> float:
        r"""

        returns the log10 of the domain size of the model defined as the product of the domain sizes of the variables in the model.

        Returns
        -------
        float
        	the log10 domain size.

        """
        return _bn.BayesNet_log10DomainSize(self)

    def ids(self, names: List[str]) -> object:
        r"""

        List of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        List[int]
        	The ids for the list of names of the graph variables

        """
        return _bn.BayesNet_ids(self, names)

    def nodeset(self, names: List[str]) -> object:
        r"""

        Set of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        Set[int]
        	The set of ids for the list of names of the graph variables

        """
        return _bn.BayesNet_nodeset(self, names)

    def minimalCondSet(self, *args) -> object:
        r"""

        Returns, given one or many targets and a list of variables, the minimal set of those needed to calculate the target/targets.

        Parameters
        ----------
        target : int
        	The id of the target
        targets : List[int]
        	The ids of the targets
        list : List[int]
        	The list of available variables

        Returns
        -------
        Set[int]
        	The minimal set of variables

        """
        return _bn.BayesNet_minimalCondSet(self, *args)

    def isIndependent(self, *args) -> bool:
        r"""

        check if nodes X and nodes Y are independent given nodes Z

        Parameters
        ----------
        X : str|intList[str|int]
              a list of of nodeIds or names
        Y : str|intList[str|int]
              a list of of nodeIds or names
        Z : str|intList[str|int]
              a list of of nodeIds or names

        Raises
        ------
        InvalidArgument
          if X and Y share variables

        Returns
        -------
        bool
          True if X and Y are independent given Z in the model

        """
        return _bn.BayesNet_isIndependent(self, *args)

    def names(self) -> object:
        r"""

        Set of names of variables in the model

        Returns
        -------
        Set[str]
        	The names of the graph variables

        """
        return _bn.BayesNet_names(self)

    def __iter__(self):
      """
      Iterate over the variables of the model

      Yield
      -----
      Tuple[int,str]
        The index of the variable and its name
      """
      for i in self.nodes():
        yield i,self.variable(i).name()

    def __getitem__(self, key):
      if isinstance(key, int):
        return self.variable(key)
      elif isinstance(key, str):
        return self.variableFromName(key)
      else:
        raise TypeError("key must be an int or a string")


    def nodes(self) -> object:
        r"""

        Returns
        -------
        Set[int]
            the set of ids

        """
        return _bn.BayesNet_nodes(self)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


    def arcs(self) -> object:
        r"""

        Returns
        -------
        list
        	The lisf of arcs in the IBayesNet

        """
        return _bn.BayesNet_arcs(self)

    def parents(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id :
        	The id of the child node

        Returns
        -------
        Set
            the set of the parents ids.

        """
        return _bn.BayesNet_parents(self, norid)

    def children(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id : int
          the id of the parent

        Returns
        -------
        Set
        	the set of all the children

        """
        return _bn.BayesNet_children(self, norid)

    def family(self, norid: object) -> object:
        r"""

        give the set of parents of a node and the node

        Parameters
        ---------
        norid : str|int
          the node

        Returns
        -------
        Set[int]
          the set of nodeId of the family of the node `norid`

        """
        return _bn.BayesNet_family(self, norid)

    def descendants(self, norid: object) -> object:
        r"""

        give the set of nodeid of descendants of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the descendants of node `norid`.

        """
        return _bn.BayesNet_descendants(self, norid)

    def ancestors(self, norid: object) -> object:
        r"""

        give the set of nodeid of ancestors of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the ancestors of node `norid`.

        """
        return _bn.BayesNet_ancestors(self, norid)

    def moralizedAncestralGraph(self, nodes: object) -> "pyagrum.UndiGraph":
        r"""

        build a UndiGraph by moralizing the Ancestral Graph of a list of nodes

        Parameters
        ----------
        nodes : str|intList[str|int]
          the list of of nodeIds or names

        Warnings
        --------
          pyagrum.UndiGraph only knows NodeId. Hence the moralized ancestral graph does not include the names of the variables.graph

        Returns
        -------
        pyagrum.UndiGraph
          the moralized ancestral graph of the nodes

        """
        return _bn.BayesNet_moralizedAncestralGraph(self, nodes)

    def addVariables(self,listFastVariables,default_nbr_mod=2):
       """
       Add a list of variable in the form of 'fast' syntax.

       Parameters
       ----------
       listFastVariables: List[str]
         the list of variables in 'fast' syntax.
       default_nbr_mod: int
         the number of modalities for the variable if not specified following :ref:`fast syntax<Quick specification of (randomly parameterized) graphical models>`. Note that default_nbr_mod=1 is
         mandatory to create variables with only one modality (for utility for instance).

       Returns
       -------
       List[int]
         the list of created ids.
       """
       return [self.add(descr,default_nbr_mod) for descr in listFastVariables]

    def addArcs(self,listArcs):
      """
      add a list of arcs in te model.

      Parameters
      ----------
      listArcs : List[Tuple[intstr,intstr]]
        the list of arcs
      """
      self.beginTopologyTransformation()
      for arc in listArcs:
        self.addArc(*arc)
      self.endTopologyTransformation()

    def addStructureListener(self,whenNodeAdded=None,whenNodeDeleted=None,whenArcAdded=None,whenArcDeleted=None):
        """
        Add the listeners in parameters to the list of existing ones.

        Parameters
        ----------
        whenNodeAdded : lambda expression
          a function for when a node is added
        whenNodeDeleted : lambda expression
          a function for when a node is removed
        whenArcAdded : lambda expression
          a function for when an arc is added
        whenArcDeleted : lambda expression
          a function for when an arc is removed
        """
        if [whenNodeAdded,whenNodeDeleted,whenArcAdded,whenArcDeleted]==[None,None,None,None]:
          return

        if not hasattr(self,"_listeners"):
          self._listeners=[]

        nl = PythonBNListener(self, self.variableNodeMap())
        if whenNodeAdded is not None:
          nl.setWhenNodeAdded(whenNodeAdded)
        if whenNodeDeleted is not None:
          nl.setWhenNodeDeleted(whenNodeDeleted)
        if whenArcAdded is not None:
          nl.setWhenArcAdded(whenArcAdded)
        if whenArcDeleted is not None:
          nl.setWhenArcDeleted(whenArcDeleted)

        self._listeners.append(nl)


    def loadBIF(self, name: str, l: object=None) -> str:
        r"""

        Load a BIF file.

        Parameters
        ----------
        name : str
        	the file's name
        l : list
        	list of functions to execute

        Raises
        --------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadBIF(self, name, l)

    def saveBIF(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in a BIF file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveBIF(self, name, allowModificationWhenSaving)

    def loadDSL(self, name: str, l: object=None) -> str:
        r"""

        Load a DSL file.

        Parameters
        ----------
        name : str
        	the file's name
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadDSL(self, name, l)

    def loadXDSL(self, name: str, l: object=None) -> str:
        r"""

        Load a XDSL file.

        Parameters
        ----------
        name : str
        	the file's name
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadXDSL(self, name, l)

    def saveDSL(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in a DSL file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveDSL(self, name, allowModificationWhenSaving)

    def saveXDSL(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in a XDSL file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                (not used).
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveXDSL(self, name, allowModificationWhenSaving)

    def loadNET(self, name: str, l: object=None) -> str:
        r"""

        Load a NET file.

        Parameters
        ----------
        name : str
        	the name's file
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadNET(self, name, l)

    def saveNET(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in a NET file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveNET(self, name, allowModificationWhenSaving)

    def loadO3PRM(self, *args) -> str:
        r"""

        Load an O3PRM file.

        Warnings
        --------
        The O3PRM language is the only language allowing to manipulate not only DiscretizedVariable but also RangeVariable and LabelizedVariable.

        Parameters
        ----------
        name : str
        	the file's name
        system : str
        	the system's name
        classpath : str
        	the classpath
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadO3PRM(self, *args)

    def saveO3PRM(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in an O3PRM file.

        Warnings
        --------
        The O3PRM language is the only language allowing to manipulate not only DiscretizedVariable but also RangeVariable and LabelizedVariable.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveO3PRM(self, name, allowModificationWhenSaving)

    def loadBIFXML(self, name: str, l: object=None) -> str:
        r"""

        Load a BIFXML file.

        Parameters
        ----------
        name : str
        	the name's file
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadBIFXML(self, name, l)

    def saveBIFXML(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in a BIFXML file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveBIFXML(self, name, allowModificationWhenSaving)

    def loadUAI(self, name: str, l: object=None) -> str:
        r"""

        Load an UAI file.

        Parameters
        ----------
        name : str
        	the name's file
        l : list
        	list of functions to execute

        Raises
        ------
        pyagrum.IOError
            If file not found
        pyagrum.FatalError
            If file is not valid

        """
        return _bn.BayesNet_loadUAI(self, name, l)

    def saveUAI(self, name: str, allowModificationWhenSaving: bool=False) -> None:
        r"""

        Save the BayesNet in an UAI file.

        Parameters
        ----------
        name : str
        	the file's name
        allowModificationWhenSaving: bool
                False by default.
                if true, syntax errors are corrected when saving the file. If false, they throw a FatalError.

        """
        return _bn.BayesNet_saveUAI(self, name, allowModificationWhenSaving)

    def __getstate__(self):
        pyagrum.base._gum_add_properties_while_getstate_(self)
        state={"nodes":[self.variable(i).toFast() for i in self.nodes()],
               "parents":{self.variable(i).name():list(self.cpt(i).names)[1:] for i in self.nodes()},
               "cpt":{self.variable(i).name():self.cpt(i)[:].flatten().tolist() for i in self.nodes()},
               "properties":{k:self.property(k) for k in self.properties()}
              }
        return state

    def __setstate__(self,state):
        self.__init__()
        for fastvar in state['nodes']:
            self.add(fastvar)
        self.beginTopologyTransformation()
        for son in state['parents']:
            for father in state['parents'][son]:
                self.addArc(father,son)
        self.endTopologyTransformation()
        for node in state['cpt']:
            self.cpt(node).fillWith(state['cpt'][node])
        for prop in state['properties']:
            self.setProperty(prop,state['properties'][prop])
        return self

    def toFast(self, filename: str = None) -> str:
      """
      Export the Bayesian network as *fast* syntax (in a string or in a python file)

      Parameters
      ----------
      filename : Optional[str]
        the name of the file (including the prefix), if None , use sys.stdout
      """

      def _toFastBN(bn,pythoncode=False):
        res = []
        sovars = set()
        for x, y in bn.arcs():
          if x in sovars:
            src = bn.variable(x).name()
          else:
            src = bn.variable(x).toFast()
            sovars.add(x)
          if y in sovars:
            dst = bn.variable(y).name()
          else:
            dst = bn.variable(y).toFast()
            sovars.add(y)
          res.append(f"{src}->{dst}")

        for x in bn.nodes():
          if x not in sovars:
            res .append(bn.variable(x).toFast())

        if pythoncode:
          return 'model=pyagrum.fastBN("""'+';\n     '.join(res)+'""")'
        else:
          return ';'.join(res)

      if filename is None:
        return _toFastBN(self)
      else:
        with open(filename, "w") as pyfile:
          print(_toFastBN(self,pythoncode=True), file=pyfile)


    def __repr__(self) -> str:
        return _bn.BayesNet___repr__(self)

    def __str__(self) -> str:
        return _bn.BayesNet___str__(self)

# Register BayesNet in _bn:
_bn.BayesNet_swigregister(BayesNet)
class BayesNetFragment(IBayesNet, ):
    r"""

    BayesNetFragment represents a part of a Bayesian network (subset of nodes). By default, the arcs and the CPTs are the same as the BN but local CPTs can be build to express different local dependencies. All the non local CPTs are not copied. Therefore a BayesNetFragment is a light object.

    BayesNetFragment(BayesNet bn) -> BayesNetFragment
        Parameters:
          - **bn** (*pyagrum.BayesNet*) -- the bn refered by the fragment

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.BayesNetFragment_swiginit(self, _bn.new_BayesNetFragment(bn))
    __swig_destroy__ = _bn.delete_BayesNetFragment

    def whenNodeAdded(self, src: object, id: int) -> None:
        return _bn.BayesNetFragment_whenNodeAdded(self, src, id)

    def whenNodeDeleted(self, src: object, id: int) -> None:
        return _bn.BayesNetFragment_whenNodeDeleted(self, src, id)

    def whenArcAdded(self, src: object, _from: int, to: int) -> None:
        return _bn.BayesNetFragment_whenArcAdded(self, src, _from, to)

    def whenArcDeleted(self, src: object, _from: int, to: int) -> None:
        return _bn.BayesNetFragment_whenArcDeleted(self, src, _from, to)

    def cpt(self, *args) -> "pyagrum.Tensor":
        r"""

        Returns the CPT of a variable.

        Parameters
        ----------
        VarId : int
        	A variable's id in the pyagrum.IBayesNet.
        name : str
        	A variable's name in the pyagrum.IBayesNet.

        Returns
        -------
        pyagrum.Tensor
        	The variable's CPT.

        Raises
        ------
        pyagrum.NotFound
        	If no variable's id matches varId.

        """
        return _bn.BayesNetFragment_cpt(self, *args)

    def variableNodeMap(self) -> "pyagrum.VariableNodeMap":
        r"""

        Returns
        -------
        pyagrum.variableNodeMap
        	the variable node map

        """
        return _bn.BayesNetFragment_variableNodeMap(self)

    def variable(self, *args) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        id : int
        	a variable's id
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNetFragment_variable(self, *args)

    def nodeId(self, var: "pyagrum.DiscreteVariable") -> int:
        r"""

        Parameters
        ----------
        var : pyagrum.DiscreteVariable
        	a variable

        Returns
        -------
        int
        	the id of the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNetFragment_nodeId(self, var)

    def idFromName(self, name: str) -> int:
        r"""

        Returns a variable's id given its name in the graph.

        Parameters
        ----------
        name : str
        	The variable's name from which the id is returned.

        Notes
        -----
          A convenient shortcut for `g.variableFromName(name)` is `g[name]`.

        Returns
        -------
        int :
        	The variable's node id.

        Raises
        ------
        pyagrum.NotFound
        	If name does not match a variable in the graph

        """
        return _bn.BayesNetFragment_idFromName(self, name)

    def variableFromName(self, name: str) -> "pyagrum.DiscreteVariable":
        r"""

        Parameters
        ----------
        name : str
        	a variable's name

        Returns
        -------
        pyagrum.DiscreteVariable
        	the variable

        Raises
        ------
        pyagrum.IndexError
        	If the graph does not contain the variable

        """
        return _bn.BayesNetFragment_variableFromName(self, name)

    def toDot(self) -> str:
        r"""

        Returns
        -------
        str
            a friendly display of the graph in DOT format

        """
        return _bn.BayesNetFragment_toDot(self)

    def isInstalledNode(self, *args) -> bool:
        r"""

        Check if a node is in the fragment

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.

        """
        return _bn.BayesNetFragment_isInstalledNode(self, *args)

    def installNode(self, *args) -> None:
        r"""

        Add a node to the fragment. The arcs that can be added between installed nodes are created.
        No specific CPT are created. Then either the parents of the node are already in the fragment
        and the node is consistant, or the parents are not in the fragment and the node is not consistant.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.

        Raises
        ------
        pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_installNode(self, *args)

    def installAscendants(self, *args) -> None:
        r"""

        Add the variable and all its ascendants in the fragment. No inconsistant node are created.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.

        Raises
        ------
          pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_installAscendants(self, *args)

    def uninstallNode(self, *args) -> None:
        r"""

        Remove a node from the fragment. The fragment can become inconsistant.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.

        Raises
        ------
        pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_uninstallNode(self, *args)

    def installMarginal(self, *args) -> None:
        r"""

        Install a local marginal for a node. Doing so, it removes the parents of the node in the fragment.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.
        pot : Tensor
          the Tensor (marginal) to install

        Raises
        ------
        pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_installMarginal(self, *args)

    def installCPT(self, *args) -> None:
        r"""

        Install a local CPT for a node. Doing so, it changes the parents of the node in the fragment.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.
        pot : Tensor
          the Tensor to install

        Raises
        ------
        pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_installCPT(self, *args)

    def uninstallCPT(self, *args) -> None:
        r"""

        Remove a local CPT. The fragment can become inconsistant.

        Parameters
        ----------
        n : int, str
        	the id or the name of the variable.

        Raises
        ------
        pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_uninstallCPT(self, *args)

    def checkConsistency(self, *args) -> bool:
        r"""

        If a variable is added to the fragment but not its parents, there is no CPT consistant for this variable. This function checks the consistency for a variable of for all.

        Parameters
        ----------

        n : int, str (optional)
        	the id or the name of the variable. If no argument, the function checks all the variables.

        Returns
        -------
        boolean
        	True if the variable(s) is consistant.

        Raises
        ------
          pyagrum.NotFound
          if the node is not found.

        """
        return _bn.BayesNetFragment_checkConsistency(self, *args)

    def toBN(self) -> "pyagrum.BayesNet":
        r"""

        Create a BayesNet from a fragment.

        Raises
        ------
        pyagrum.OperationNotAllowed
          if the fragment is not consistent.

        """
        return _bn.BayesNetFragment_toBN(self)

    def dag(self) -> "pyagrum.DAG":
        r"""

        Returns
        -------
        pyagrum.DAG
        	a constant reference to the dag of this BayesNet.

        """
        val = _bn.BayesNetFragment_dag(self)

        from pyagrum.base import DAG
        val = DAG(val) # copying the DAG


        return val


    def ids(self, names: List[str]) -> object:
        r"""

        List of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        List[int]
        	The ids for the list of names of the graph variables

        """
        return _bn.BayesNetFragment_ids(self, names)

    def nodeset(self, names: List[str]) -> object:
        r"""

        Set of ids for a list of names of variables in the model

        Parameters
        ----------
        lov : List[str]
          List of variable names

        Returns
        -------
        Set[int]
        	The set of ids for the list of names of the graph variables

        """
        return _bn.BayesNetFragment_nodeset(self, names)

    def minimalCondSet(self, *args) -> object:
        r"""

        Returns, given one or many targets and a list of variables, the minimal set of those needed to calculate the target/targets.

        Parameters
        ----------
        target : int
        	The id of the target
        targets : List[int]
        	The ids of the targets
        list : List[int]
        	The list of available variables

        Returns
        -------
        Set[int]
        	The minimal set of variables

        """
        return _bn.BayesNetFragment_minimalCondSet(self, *args)

    def isIndependent(self, *args) -> bool:
        r"""

        check if nodes X and nodes Y are independent given nodes Z

        Parameters
        ----------
        X : str|intList[str|int]
              a list of of nodeIds or names
        Y : str|intList[str|int]
              a list of of nodeIds or names
        Z : str|intList[str|int]
              a list of of nodeIds or names

        Raises
        ------
        InvalidArgument
          if X and Y share variables

        Returns
        -------
        bool
          True if X and Y are independent given Z in the model

        """
        return _bn.BayesNetFragment_isIndependent(self, *args)

    def names(self) -> object:
        r"""

        Set of names of variables in the model

        Returns
        -------
        Set[str]
        	The names of the graph variables

        """
        return _bn.BayesNetFragment_names(self)

    def __iter__(self):
      """
      Iterate over the variables of the model

      Yield
      -----
      Tuple[int,str]
        The index of the variable and its name
      """
      for i in self.nodes():
        yield i,self.variable(i).name()

    def __getitem__(self, key):
      if isinstance(key, int):
        return self.variable(key)
      elif isinstance(key, str):
        return self.variableFromName(key)
      else:
        raise TypeError("key must be an int or a string")


    def nodes(self) -> object:
        r"""

        Returns
        -------
        Set[int]
            the set of ids

        """
        return _bn.BayesNetFragment_nodes(self)

    def connectedComponents(self):
      """ connected components from a graph/graphical models

      Compute the connected components of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      The firstly visited node for each component is called a 'root' and is used as a key for the component.
      This root has been arbitrarily chosen during the algorithm.

      Returns
      -------
      dict(int,Set[int])
        dict of connected components (as set of nodeIds (int)) with a nodeId (root) of each component as key.

      """
      nodes=self.nodes()
      connected_components=dict()

      def parcours(node,orig):
          cc={node}
          nodes.discard(node)
          if hasattr(self,'children'):
              for chi in self.children(node):
                  if chi!=orig:
                      if chi in nodes:
                          cc|=parcours(chi,node)

          if hasattr(self,'parents'):
              for par in self.parents(node):
                  if par!=orig:
                      if par in nodes:
                          cc|=parcours(par,node)

          if hasattr(self,'neighbours'):
              for nei in self.neighbours(node):
                  if nei!=orig:
                      if nei in nodes:
                          cc|=parcours(nei,node)
          return cc

      while (len(nodes)>0):
          root=nodes.pop()
          connected_components[root]=parcours(root,None)
      return connected_components

    def adjacencyMatrix(self):
      """ adjacency matrix from a graph/graphical models

      Compute the adjacency matrix of a pyAgrum's graph or graphical models
      (more generally an object that has `nodes`, `children`/`parents` or `neighbours` methods)

      Returns
      -------
      numpy.ndarray
        adjacency matrix (as numpy.ndarray) with nodeId as key.

      """
      import numpy as np
      nodes=self.nodes()
      n=self.size()
      am=np.zeros((n,n)).astype(int)

      for node in nodes:
          if hasattr(self,'children'):
              for children in self.children(node):
                  am[node,children]=1
          if hasattr(self,'neighbours'):
              for neighbour in self.neighbours(node):
                  am[node,neighbour]=1
      return am


    def arcs(self) -> object:
        r"""

        Returns
        -------
        list
        	The lisf of arcs in the IBayesNet

        """
        return _bn.BayesNetFragment_arcs(self)

    def parents(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id :
        	The id of the child node

        Returns
        -------
        Set
            the set of the parents ids.

        """
        return _bn.BayesNetFragment_parents(self, norid)

    def children(self, norid: object) -> object:
        r"""

        Parameters
        ----------
        id : int
          the id of the parent

        Returns
        -------
        Set
        	the set of all the children

        """
        return _bn.BayesNetFragment_children(self, norid)

    def family(self, norid: object) -> object:
        r"""

        give the set of parents of a node and the node

        Parameters
        ---------
        norid : str|int
          the node

        Returns
        -------
        Set[int]
          the set of nodeId of the family of the node `norid`

        """
        return _bn.BayesNetFragment_family(self, norid)

    def descendants(self, norid: object) -> object:
        r"""

        give the set of nodeid of descendants of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the descendants of node `norid`.

        """
        return _bn.BayesNetFragment_descendants(self, norid)

    def ancestors(self, norid: object) -> object:
        r"""

        give the set of nodeid of ancestors of a node

        Parameters
        ----------
        norid : str|int
          the name or the id of the node

        Returns
        -------
        Set[int]
          the set of ids of the ancestors of node `norid`.

        """
        return _bn.BayesNetFragment_ancestors(self, norid)

    def moralizedAncestralGraph(self, nodes: object) -> "pyagrum.UndiGraph":
        r"""

        build a UndiGraph by moralizing the Ancestral Graph of a list of nodes

        Parameters
        ----------
        nodes : str|intList[str|int]
          the list of of nodeIds or names

        Warnings
        --------
          pyagrum.UndiGraph only knows NodeId. Hence the moralized ancestral graph does not include the names of the variables.graph

        Returns
        -------
        pyagrum.UndiGraph
          the moralized ancestral graph of the nodes

        """
        return _bn.BayesNetFragment_moralizedAncestralGraph(self, nodes)

    def addVariables(self,listFastVariables,default_nbr_mod=2):
       """
       Add a list of variable in the form of 'fast' syntax.

       Parameters
       ----------
       listFastVariables: List[str]
         the list of variables in 'fast' syntax.
       default_nbr_mod: int
         the number of modalities for the variable if not specified following :ref:`fast syntax<Quick specification of (randomly parameterized) graphical models>`. Note that default_nbr_mod=1 is
         mandatory to create variables with only one modality (for utility for instance).

       Returns
       -------
       List[int]
         the list of created ids.
       """
       return [self.add(descr,default_nbr_mod) for descr in listFastVariables]

    def addArcs(self,listArcs):
      """
      add a list of arcs in te model.

      Parameters
      ----------
      listArcs : List[Tuple[intstr,intstr]]
        the list of arcs
      """
      self.beginTopologyTransformation()
      for arc in listArcs:
        self.addArc(*arc)
      self.endTopologyTransformation()

    def addStructureListener(self,whenNodeAdded=None,whenNodeDeleted=None,whenArcAdded=None,whenArcDeleted=None):
        """
        Add the listeners in parameters to the list of existing ones.

        Parameters
        ----------
        whenNodeAdded : lambda expression
          a function for when a node is added
        whenNodeDeleted : lambda expression
          a function for when a node is removed
        whenArcAdded : lambda expression
          a function for when an arc is added
        whenArcDeleted : lambda expression
          a function for when an arc is removed
        """
        if [whenNodeAdded,whenNodeDeleted,whenArcAdded,whenArcDeleted]==[None,None,None,None]:
          return

        if not hasattr(self,"_listeners"):
          self._listeners=[]

        nl = PythonBNListener(self, self.variableNodeMap())
        if whenNodeAdded is not None:
          nl.setWhenNodeAdded(whenNodeAdded)
        if whenNodeDeleted is not None:
          nl.setWhenNodeDeleted(whenNodeDeleted)
        if whenArcAdded is not None:
          nl.setWhenArcAdded(whenArcAdded)
        if whenArcDeleted is not None:
          nl.setWhenArcDeleted(whenArcDeleted)

        self._listeners.append(nl)


# Register BayesNetFragment in _bn:
_bn.BayesNetFragment_swigregister(BayesNetFragment)
class LazyPropagation(object):
    r"""

    Class used for Lazy Propagation

    LazyPropagation(bn) -> LazyPropagation
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.LazyPropagation_swiginit(self, _bn.new_LazyPropagation(*args))

        self._model=args[0]



    __swig_destroy__ = _bn.delete_LazyPropagation

    def setTriangulation(self, new_triangulation: "pyagrum.Triangulation") -> None:
        return _bn.LazyPropagation_setTriangulation(self, new_triangulation)

    def setRelevantTensorsFinderType(self, type: int) -> None:
        r"""

        sets how we determine the relevant tensors to combine

        When a clique sends a message to a separator, it first constitute the set of the tensors it contains and of the tensors contained in the messages it received. If RelevantTensorsFinderType = FIND_ALL, all these tensors are combined and projected to produce the message sent to the separator. If RelevantTensorsFinderType = DSEP_BAYESBALL_NODES, then only the set of tensors d-connected to the variables of the separator are kept for combination and projection.

        0 = FIND_ALL
        1 = DSEP_BAYESBALL_NODES
        2 = DSEP_BAYESBALL_TENSORS
        3 = DSEP_KOLLER_FRIEDMAN_2009

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.LazyPropagation_setRelevantTensorsFinderType(self, type)

    def setFindBarrenNodesType(self, type: int) -> None:
        r"""

        sets how we determine barren nodes

        Barren nodes are unnecessary for probability inference, so they can be safely discarded in this case (type = FIND_BARREN_NODES). This speeds-up inference. However, there are some cases in which we do not want to remove barren nodes, typically when we want to answer queries such as Most Probable Explanations (MPE).

        0 = FIND_NO_BARREN_NODES
        1 = FIND_BARREN_NODES

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.LazyPropagation_setFindBarrenNodesType(self, type)

    def joinTree(self) -> "pyagrum.CliqueGraph":
        r"""

        Returns
        -------
        pyagrum.CliqueGraph
          the current join tree used

        """
        return _bn.LazyPropagation_joinTree(self)

    def junctionTree(self) -> "pyagrum.JunctionTree":
        r"""

        Returns
        -------
        pyagrum.CliqueGraph
          the current junction tree

        """
        val = _bn.LazyPropagation_junctionTree(self)

        val._engine=self


        return val


    def evidenceProbability(self) -> float:
        r"""

        Returns
        -------
        float
          the probability of evidence

        """
        return _bn.LazyPropagation_evidenceProbability(self)

    def mpe(self) -> "pyagrum.Instantiation":
        r"""

        Find the Most Probable Explanation (MPE) given the evidence (if any) added into LazyPropagation

        Returns
        -------
        pyagrum.Instantiation
          An instantiation of all the variables of the Bayes net representing the Most Probable Explanation.

        """
        return _bn.LazyPropagation_mpe(self)

    def mpeLog2Posterior(self) -> Tuple["pyagrum.Instantiation",float]:
        r"""

        Find the Most Probable Explanation (MPE) given the evidence (if any) added into LazyPropagation as well as the log2 of its posterior probability

        Returns
        -------
        Tuple[pyagrum.Instantiation, float]
            A tuple with the instantiation of all the variables of the Bayes net representing the Most Probable Explanation and the log2 of its posterior probability

        """
        return _bn.LazyPropagation_mpeLog2Posterior(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LazyPropagation_makeInference(self)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LazyPropagation_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LazyPropagation_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LazyPropagation_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LazyPropagation_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LazyPropagation_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LazyPropagation_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LazyPropagation_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LazyPropagation_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LazyPropagation_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LazyPropagation_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LazyPropagation_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LazyPropagation_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LazyPropagation_BN(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LazyPropagation_posterior(self, *args)

    def eraseAllJointTargets(self) -> None:
        r"""

        Clear all previously defined joint targets.

        """
        return _bn.LazyPropagation_eraseAllJointTargets(self)

    def eraseAllMarginalTargets(self) -> None:
        r"""

        Clear all the previously defined marginal targets.

        """
        return _bn.LazyPropagation_eraseAllMarginalTargets(self)

    def nbrJointTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of joint targets

        """
        return _bn.LazyPropagation_nbrJointTargets(self)

    def setNumberOfThreads(self, nb: int) -> None:
        r"""

        If the argument nb is different from 0, this number of threads will be used during inferences, hence overriding aGrUM's default number of threads.
        If, on the contrary, nb is equal to 0, the parallelized inference engine will comply with aGrUM's default number of threads.

        Parameters
        ----------
        nb : int
        	the number of threads to be used by ShaferShenoyMRFInference

        """
        return _bn.LazyPropagation_setNumberOfThreads(self, nb)

    def getNumberOfThreads(self) -> int:
        r"""

        returns the number of threads used by LazyPropagation during inferences.

        Returns
        -------
        int
        	the number of threads used by LazyPropagation during inferences

        """
        return _bn.LazyPropagation_getNumberOfThreads(self)

    def isGumNumberOfThreadsOverriden(self) -> bool:
        r"""

        Indicates whether LazyPropagation currently overrides aGrUM's default number of threads (see method setNumberOfThreads).

        Returns
        -------
        bool
        	A Boolean indicating whether LazyPropagation currently overrides aGrUM's default number of threads

        """
        return _bn.LazyPropagation_isGumNumberOfThreadsOverriden(self)

    def setMaxMemory(self, gigabytes: int) -> None:
        r"""

        sets an upper bound on the memory consumption admissible

        Parameters
        ----------
        gigabytes: float
          this upper bound in gigabytes.

        """
        return _bn.LazyPropagation_setMaxMemory(self, gigabytes)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LazyPropagation_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LazyPropagation_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LazyPropagation_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LazyPropagation_evidenceImpact(self, *args)

    def jointMutualInformation(self, targets: object) -> float:
        return _bn.LazyPropagation_jointMutualInformation(self, targets)

    def evidenceJointImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(joint targets|evs) (for all instanciation of targets and evs)

        Parameters
        ----------
        targets : List[intstr]
          a list of node Ids or node names
        evs : Set[intstr]
          a set of nodes ids or names.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(target|evs)

        Raises
        ------
        pyagrum.Exception
          If some evidene entered into the Bayes net are incompatible (their joint proba = 0)

        """
        return _bn.LazyPropagation_evidenceJointImpact(self, *args)

    def jointPosterior(self, targets: object) -> "pyagrum.Tensor":
        r"""

        Compute the joint posterior of a set of nodes.

        Parameters
        ----------
        list :
          the list of nodes whose posterior joint probability is wanted


        Warnings
        --------
        The order of the variables given by the list here or when the jointTarget is declared can not be assumed to be used by the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior joint probability of the set of nodes.

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LazyPropagation_jointPosterior(self, targets)

    def addJointTarget(self, targets: object) -> None:
        r"""

        Add a list of nodes as a new joint target. As a collateral effect, every node is added as a marginal target.

        Parameters
        ----------
        list
          a list of names of nodes

        Raises
        ------
        pyagrum.UndefinedElement
          If some node(s) do not belong to the Bayesian network

        """
        return _bn.LazyPropagation_addJointTarget(self, targets)

    def eraseJointTarget(self, targets: object) -> None:
        r"""

        Remove, if existing, the joint target.

        Parameters
        ----------
        list
          a list of names or Ids of nodes

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LazyPropagation_eraseJointTarget(self, targets)

    def isJointTarget(self, targets: object) -> bool:
        r"""

        Parameters
        ----------
        list
          a list of nodes ids or names.

        Returns
        -------
        bool
          True if target is a joint target.

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LazyPropagation_isJointTarget(self, targets)

    def jointTargets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of target sets

        """
        return _bn.LazyPropagation_jointTargets(self)

# Register LazyPropagation in _bn:
_bn.LazyPropagation_swigregister(LazyPropagation)
class ShaferShenoyInference(object):
    r"""

    Class used for Shafer-Shenoy inferences.

    ShaferShenoyInference(bn) -> ShaferShenoyInference
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.ShaferShenoyInference_swiginit(self, _bn.new_ShaferShenoyInference(*args))

        self._model=args[0]



    __swig_destroy__ = _bn.delete_ShaferShenoyInference

    def setTriangulation(self, new_triangulation: "pyagrum.Triangulation") -> None:
        return _bn.ShaferShenoyInference_setTriangulation(self, new_triangulation)

    def setRelevantTensorsFinderType(self, type: int) -> None:
        r"""

        sets how we determine the relevant tensors to combine

        When a clique sends a message to a separator, it first constitute the set of the tensors it contains and of the tensors contained in the messages it received. If RelevantTensorsFinderType = FIND_ALL, all these tensors are combined and projected to produce the message sent to the separator. If RelevantTensorsFinderType = DSEP_BAYESBALL_NODES, then only the set of tensors d-connected to the variables of the separator are kept for combination and projection.

        0 = FIND_ALL
        1 = DSEP_BAYESBALL_NODES
        2 = DSEP_BAYESBALL_TENSORS
        3 = DSEP_KOLLER_FRIEDMAN_2009

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.ShaferShenoyInference_setRelevantTensorsFinderType(self, type)

    def setFindBarrenNodesType(self, type: int) -> None:
        r"""

        sets how we determine barren nodes

        Barren nodes are unnecessary for probability inference, so they can be safely discarded in this case (type = FIND_BARREN_NODES). This speeds-up inference. However, there are some cases in which we do not want to remove barren nodes, typically when we want to answer queries such as Most Probable Explanations (MPE).

        0 = FIND_NO_BARREN_NODES
        1 = FIND_BARREN_NODES

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.ShaferShenoyInference_setFindBarrenNodesType(self, type)

    def joinTree(self) -> "pyagrum.CliqueGraph":
        r"""

        Returns
        -------
        pyagrum.CliqueGraph
          the current join tree used

        """
        return _bn.ShaferShenoyInference_joinTree(self)

    def junctionTree(self) -> "pyagrum.JunctionTree":
        r"""

        Returns
        -------
        pyagrum.CliqueGraph
          the current junction tree

        """
        val = _bn.ShaferShenoyInference_junctionTree(self)

        val._engine=self


        return val


    def evidenceProbability(self) -> float:
        r"""

        Returns
        -------
        float
          the probability of evidence

        """
        return _bn.ShaferShenoyInference_evidenceProbability(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.ShaferShenoyInference_makeInference(self)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.ShaferShenoyInference_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.ShaferShenoyInference_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.ShaferShenoyInference_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.ShaferShenoyInference_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.ShaferShenoyInference_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.ShaferShenoyInference_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.ShaferShenoyInference_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ShaferShenoyInference_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ShaferShenoyInference_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.ShaferShenoyInference_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.ShaferShenoyInference_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.ShaferShenoyInference_BN(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.ShaferShenoyInference_posterior(self, *args)

    def eraseAllJointTargets(self) -> None:
        r"""

        Clear all previously defined joint targets.

        """
        return _bn.ShaferShenoyInference_eraseAllJointTargets(self)

    def eraseAllMarginalTargets(self) -> None:
        r"""

        Clear all the previously defined marginal targets.

        """
        return _bn.ShaferShenoyInference_eraseAllMarginalTargets(self)

    def nbrJointTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of joint targets

        """
        return _bn.ShaferShenoyInference_nbrJointTargets(self)

    def setNumberOfThreads(self, nb: int) -> None:
        r"""

        If the argument nb is different from 0, this number of threads will be used during inferences, hence overriding aGrUM's default number of threads.
        If, on the contrary, nb is equal to 0, the parallelized inference engine will comply with aGrUM's default number of threads.

        Parameters
        ----------
        nb : int
        	the number of threads to be used by ShaferShenoyMRFInference

        """
        return _bn.ShaferShenoyInference_setNumberOfThreads(self, nb)

    def getNumberOfThreads(self) -> int:
        r"""

        returns the number of threads used by LazyPropagation during inferences.

        Returns
        -------
        int
        	the number of threads used by LazyPropagation during inferences

        """
        return _bn.ShaferShenoyInference_getNumberOfThreads(self)

    def isGumNumberOfThreadsOverriden(self) -> bool:
        r"""

        Indicates whether LazyPropagation currently overrides aGrUM's default number of threads (see method setNumberOfThreads).

        Returns
        -------
        bool
        	A Boolean indicating whether LazyPropagation currently overrides aGrUM's default number of threads

        """
        return _bn.ShaferShenoyInference_isGumNumberOfThreadsOverriden(self)

    def setMaxMemory(self, gigabytes: int) -> None:
        r"""

        sets an upper bound on the memory consumption admissible

        Parameters
        ----------
        gigabytes: float
          this upper bound in gigabytes.

        """
        return _bn.ShaferShenoyInference_setMaxMemory(self, gigabytes)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.ShaferShenoyInference_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.ShaferShenoyInference_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.ShaferShenoyInference_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.ShaferShenoyInference_evidenceImpact(self, *args)

    def jointMutualInformation(self, targets: object) -> float:
        return _bn.ShaferShenoyInference_jointMutualInformation(self, targets)

    def evidenceJointImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(joint targets|evs) (for all instanciation of targets and evs)

        Parameters
        ----------
        targets : List[intstr]
          a list of node Ids or node names
        evs : Set[intstr]
          a set of nodes ids or names.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(target|evs)

        Raises
        ------
        pyagrum.Exception
          If some evidene entered into the Bayes net are incompatible (their joint proba = 0)

        """
        return _bn.ShaferShenoyInference_evidenceJointImpact(self, *args)

    def jointPosterior(self, targets: object) -> "pyagrum.Tensor":
        r"""

        Compute the joint posterior of a set of nodes.

        Parameters
        ----------
        list :
          the list of nodes whose posterior joint probability is wanted


        Warnings
        --------
        The order of the variables given by the list here or when the jointTarget is declared can not be assumed to be used by the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior joint probability of the set of nodes.

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.ShaferShenoyInference_jointPosterior(self, targets)

    def addJointTarget(self, targets: object) -> None:
        r"""

        Add a list of nodes as a new joint target. As a collateral effect, every node is added as a marginal target.

        Parameters
        ----------
        list
          a list of names of nodes

        Raises
        ------
        pyagrum.UndefinedElement
          If some node(s) do not belong to the Bayesian network

        """
        return _bn.ShaferShenoyInference_addJointTarget(self, targets)

    def eraseJointTarget(self, targets: object) -> None:
        r"""

        Remove, if existing, the joint target.

        Parameters
        ----------
        list
          a list of names or Ids of nodes

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ShaferShenoyInference_eraseJointTarget(self, targets)

    def isJointTarget(self, targets: object) -> bool:
        r"""

        Parameters
        ----------
        list
          a list of nodes ids or names.

        Returns
        -------
        bool
          True if target is a joint target.

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ShaferShenoyInference_isJointTarget(self, targets)

    def jointTargets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of target sets

        """
        return _bn.ShaferShenoyInference_jointTargets(self)

# Register ShaferShenoyInference in _bn:
_bn.ShaferShenoyInference_swigregister(ShaferShenoyInference)
class VariableElimination(object):
    r"""

    Class used for Variable Elimination inference algorithm.

    Warnings
    --------
      Even if this inference has the same API than the other (exact) inferences, its mode of operation is different and is specifically dedicated to the calculation of a single posterior. Any other use (for instance for multiple targets) is possibly inefficient.

    VariableElimination(bn) -> VariableElimination
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.VariableElimination_swiginit(self, _bn.new_VariableElimination(*args))

        self._model=args[0]



    __swig_destroy__ = _bn.delete_VariableElimination

    def setTriangulation(self, new_triangulation: "pyagrum.Triangulation") -> None:
        return _bn.VariableElimination_setTriangulation(self, new_triangulation)

    def setRelevantTensorsFinderType(self, type: int) -> None:
        r"""

        sets how we determine the relevant tensors to combine

        When a clique sends a message to a separator, it first constitute the set of the tensors it contains and of the tensors contained in the messages it received. If RelevantTensorsFinderType = FIND_ALL, all these tensors are combined and projected to produce the message sent to the separator. If RelevantTensorsFinderType = DSEP_BAYESBALL_NODES, then only the set of tensors d-connected to the variables of the separator are kept for combination and projection.

        0 = FIND_ALL
        1 = DSEP_BAYESBALL_NODES
        2 = DSEP_BAYESBALL_TENSORS
        3 = DSEP_KOLLER_FRIEDMAN_2009

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.VariableElimination_setRelevantTensorsFinderType(self, type)

    def setFindBarrenNodesType(self, type: int) -> None:
        r"""

        sets how we determine barren nodes

        Barren nodes are unnecessary for probability inference, so they can be safely discarded in this case (type = FIND_BARREN_NODES). This speeds-up inference. However, there are some cases in which we do not want to remove barren nodes, typically when we want to answer queries such as Most Probable Explanations (MPE).

        0 = FIND_NO_BARREN_NODES
        1 = FIND_BARREN_NODES

        Parameters
        ----------
        type : int
          the finder type

        Raises
        ------
        pyagrum.InvalidArgument
          If type is not implemented

        """
        return _bn.VariableElimination_setFindBarrenNodesType(self, type)

    def junctionTree(self, id: int) -> "pyagrum.JunctionTree":
        r"""

        Returns
        -------
        pyagrum.CliqueGraph
          the current junction tree

        """
        val = _bn.VariableElimination_junctionTree(self, id)

        val._engine=self


        return val


    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.VariableElimination_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.VariableElimination_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.VariableElimination_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.VariableElimination_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.VariableElimination_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.VariableElimination_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.VariableElimination_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.VariableElimination_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.VariableElimination_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.VariableElimination_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.VariableElimination_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.VariableElimination_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.VariableElimination_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.VariableElimination_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.VariableElimination_BN(self)

    def setNumberOfThreads(self, nb: int) -> None:
        r"""

        If the argument nb is different from 0, this number of threads will be used during inferences, hence overriding aGrUM's default number of threads.
        If, on the contrary, nb is equal to 0, the parallelized inference engine will comply with aGrUM's default number of threads.

        Parameters
        ----------
        nb : int
        	the number of threads to be used by ShaferShenoyMRFInference

        """
        return _bn.VariableElimination_setNumberOfThreads(self, nb)

    def getNumberOfThreads(self) -> int:
        r"""

        returns the number of threads used by LazyPropagation during inferences.

        Returns
        -------
        int
        	the number of threads used by LazyPropagation during inferences

        """
        return _bn.VariableElimination_getNumberOfThreads(self)

    def isGumNumberOfThreadsOverriden(self) -> bool:
        r"""

        Indicates whether LazyPropagation currently overrides aGrUM's default number of threads (see method setNumberOfThreads).

        Returns
        -------
        bool
        	A Boolean indicating whether LazyPropagation currently overrides aGrUM's default number of threads

        """
        return _bn.VariableElimination_isGumNumberOfThreadsOverriden(self)

    def setMaxMemory(self, gigabytes: int) -> None:
        r"""

        sets an upper bound on the memory consumption admissible

        Parameters
        ----------
        gigabytes: float
          this upper bound in gigabytes.

        """
        return _bn.VariableElimination_setMaxMemory(self, gigabytes)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.VariableElimination_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.VariableElimination_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.VariableElimination_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.VariableElimination_evidenceImpact(self, *args)

    def jointMutualInformation(self, targets: object) -> float:
        return _bn.VariableElimination_jointMutualInformation(self, targets)

    def evidenceJointImpact(self, targets: object, evs: object) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(joint targets|evs) (for all instanciation of targets and evs)

        Parameters
        ----------
        targets : List[intstr]
          a list of node Ids or node names
        evs : Set[intstr]
          a set of nodes ids or names.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(target|evs)

        Raises
        ------
        pyagrum.Exception
          If some evidene entered into the Bayes net are incompatible (their joint proba = 0)

        """
        return _bn.VariableElimination_evidenceJointImpact(self, targets, evs)

    def jointPosterior(self, targets: object) -> "pyagrum.Tensor":
        r"""

        Compute the joint posterior of a set of nodes.

        Parameters
        ----------
        list :
          the list of nodes whose posterior joint probability is wanted


        Warnings
        --------
        The order of the variables given by the list here or when the jointTarget is declared can not be assumed to be used by the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior joint probability of the set of nodes.

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.VariableElimination_jointPosterior(self, targets)

    def addJointTarget(self, targets: object) -> None:
        r"""

        Add a list of nodes as a new joint target. As a collateral effect, every node is added as a marginal target.

        Parameters
        ----------
        list
          a list of names of nodes

        Raises
        ------
        pyagrum.UndefinedElement
          If some node(s) do not belong to the Bayesian network

        """
        return _bn.VariableElimination_addJointTarget(self, targets)

    def eraseJointTarget(self, targets: object) -> None:
        r"""

        Remove, if existing, the joint target.

        Parameters
        ----------
        list
          a list of names or Ids of nodes

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.VariableElimination_eraseJointTarget(self, targets)

    def isJointTarget(self, targets: object) -> bool:
        r"""

        Parameters
        ----------
        list
          a list of nodes ids or names.

        Returns
        -------
        bool
          True if target is a joint target.

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.VariableElimination_isJointTarget(self, targets)

    def jointTargets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of target sets

        """
        return _bn.VariableElimination_jointTargets(self)

# Register VariableElimination in _bn:
_bn.VariableElimination_swigregister(VariableElimination)
class GibbsSampling(object):
    r"""

    Class for making Gibbs sampling inference in Bayesian networks.

    GibbsSampling(bn) -> GibbsSampling
        Parameters:
          - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.GibbsSampling_swiginit(self, _bn.new_GibbsSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_GibbsSampling

    def setBurnIn(self, b: int) -> None:
        r"""

        Parameters
        ----------
        b : int
          size of burn in on number of iteration

        """
        return _bn.GibbsSampling_setBurnIn(self, b)

    def burnIn(self) -> int:
        r"""

        Returns
        -------
        int
          size of burn in on number of iteration

        """
        return _bn.GibbsSampling_burnIn(self)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.GibbsSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.GibbsSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.GibbsSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.GibbsSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.GibbsSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.GibbsSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.GibbsSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.GibbsSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.GibbsSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.GibbsSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.GibbsSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.GibbsSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.GibbsSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.GibbsSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.GibbsSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.GibbsSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.GibbsSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.GibbsSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.GibbsSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.GibbsSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.GibbsSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.GibbsSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.GibbsSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.GibbsSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.GibbsSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.GibbsSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.GibbsSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.GibbsSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.GibbsSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.GibbsSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.GibbsSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.GibbsSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.GibbsSampling_currentPosterior(self, *args)

    def nbrDrawnVar(self) -> int:
        r"""

        Returns
        -------
        int
          the number of variable drawn at each iteration

        """
        return _bn.GibbsSampling_nbrDrawnVar(self)

    def setNbrDrawnVar(self, _nbr: int) -> None:
        r"""

        Parameters
        ----------
        _nbr : int
          the number of variables to be drawn at each iteration

        """
        return _bn.GibbsSampling_setNbrDrawnVar(self, _nbr)

    def isDrawnAtRandom(self) -> bool:
        r"""

        Returns
        -------
        bool
          True if variables are drawn at random

        """
        return _bn.GibbsSampling_isDrawnAtRandom(self)

    def setDrawnAtRandom(self, _atRandom: bool) -> None:
        r"""

        Parameters
        ----------
        _atRandom : bool
          indicates if variables should be drawn at random

        """
        return _bn.GibbsSampling_setDrawnAtRandom(self, _atRandom)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.GibbsSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.GibbsSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.GibbsSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.GibbsSampling_evidenceImpact(self, *args)

# Register GibbsSampling in _bn:
_bn.GibbsSampling_swigregister(GibbsSampling)
class ImportanceSampling(object):
    r"""

    Class used for inferences using the Importance Sampling algorithm.

    ImportanceSampling(bn) -> ImportanceSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.ImportanceSampling_swiginit(self, _bn.new_ImportanceSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_ImportanceSampling

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.ImportanceSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.ImportanceSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.ImportanceSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.ImportanceSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.ImportanceSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.ImportanceSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.ImportanceSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.ImportanceSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.ImportanceSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.ImportanceSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.ImportanceSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.ImportanceSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.ImportanceSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.ImportanceSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.ImportanceSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.ImportanceSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.ImportanceSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.ImportanceSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.ImportanceSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.ImportanceSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.ImportanceSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.ImportanceSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.ImportanceSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.ImportanceSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.ImportanceSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.ImportanceSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.ImportanceSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ImportanceSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.ImportanceSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.ImportanceSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.ImportanceSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.ImportanceSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.ImportanceSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.ImportanceSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.ImportanceSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.ImportanceSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.ImportanceSampling_evidenceImpact(self, *args)

# Register ImportanceSampling in _bn:
_bn.ImportanceSampling_swigregister(ImportanceSampling)
class WeightedSampling(object):
    r"""

    Class used for Weighted sampling inference algorithm.

    WeightedSampling(bn) -> WeightedSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.WeightedSampling_swiginit(self, _bn.new_WeightedSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_WeightedSampling

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.WeightedSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.WeightedSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.WeightedSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.WeightedSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.WeightedSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.WeightedSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.WeightedSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.WeightedSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.WeightedSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.WeightedSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.WeightedSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.WeightedSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.WeightedSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.WeightedSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.WeightedSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.WeightedSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.WeightedSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.WeightedSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.WeightedSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.WeightedSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.WeightedSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.WeightedSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.WeightedSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.WeightedSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.WeightedSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.WeightedSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.WeightedSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.WeightedSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.WeightedSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.WeightedSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.WeightedSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.WeightedSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.WeightedSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.WeightedSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.WeightedSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.WeightedSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.WeightedSampling_evidenceImpact(self, *args)

# Register WeightedSampling in _bn:
_bn.WeightedSampling_swigregister(WeightedSampling)
class MonteCarloSampling(object):
    r"""

    Class used for Monte Carlo sampling inference algorithm.

    MonteCarloSampling(bn) -> MonteCarloSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.MonteCarloSampling_swiginit(self, _bn.new_MonteCarloSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_MonteCarloSampling

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.MonteCarloSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.MonteCarloSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.MonteCarloSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.MonteCarloSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.MonteCarloSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.MonteCarloSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.MonteCarloSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.MonteCarloSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.MonteCarloSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.MonteCarloSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.MonteCarloSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.MonteCarloSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.MonteCarloSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.MonteCarloSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.MonteCarloSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.MonteCarloSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.MonteCarloSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.MonteCarloSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.MonteCarloSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.MonteCarloSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.MonteCarloSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.MonteCarloSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.MonteCarloSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.MonteCarloSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.MonteCarloSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.MonteCarloSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.MonteCarloSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.MonteCarloSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.MonteCarloSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.MonteCarloSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.MonteCarloSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.MonteCarloSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.MonteCarloSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.MonteCarloSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.MonteCarloSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.MonteCarloSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.MonteCarloSampling_evidenceImpact(self, *args)

# Register MonteCarloSampling in _bn:
_bn.MonteCarloSampling_swigregister(MonteCarloSampling)
class LoopyImportanceSampling(ImportanceSampling):
    r"""

    Class used for inferences using a loopy version of importance sampling.

    LoopyImportanceSampling(bn) -> LoopyImportanceSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.LoopyImportanceSampling_swiginit(self, _bn.new_LoopyImportanceSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_LoopyImportanceSampling

    def makeInference_(self) -> None:
        return _bn.LoopyImportanceSampling_makeInference_(self)

    def setVirtualLBPSize(self, vlbpsize: float) -> None:
        r"""

        Parameters
        ----------
        vlbpsize : float
          the size of the virtual LBP

        """
        return _bn.LoopyImportanceSampling_setVirtualLBPSize(self, vlbpsize)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.LoopyImportanceSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.LoopyImportanceSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.LoopyImportanceSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.LoopyImportanceSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.LoopyImportanceSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyImportanceSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.LoopyImportanceSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.LoopyImportanceSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.LoopyImportanceSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.LoopyImportanceSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.LoopyImportanceSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyImportanceSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.LoopyImportanceSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.LoopyImportanceSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.LoopyImportanceSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.LoopyImportanceSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.LoopyImportanceSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LoopyImportanceSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyImportanceSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LoopyImportanceSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyImportanceSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LoopyImportanceSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LoopyImportanceSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LoopyImportanceSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LoopyImportanceSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LoopyImportanceSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LoopyImportanceSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyImportanceSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyImportanceSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LoopyImportanceSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LoopyImportanceSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LoopyImportanceSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyImportanceSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LoopyImportanceSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LoopyImportanceSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LoopyImportanceSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LoopyImportanceSampling_evidenceImpact(self, *args)

# Register LoopyImportanceSampling in _bn:
_bn.LoopyImportanceSampling_swigregister(LoopyImportanceSampling)
class LoopyWeightedSampling(WeightedSampling):
    r"""

    Class used for inferences using a loopy version of importance sampling.

    LoopyImportanceSampling(bn) -> LoopyImportanceSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.LoopyWeightedSampling_swiginit(self, _bn.new_LoopyWeightedSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_LoopyWeightedSampling

    def makeInference_(self) -> None:
        return _bn.LoopyWeightedSampling_makeInference_(self)

    def setVirtualLBPSize(self, vlbpsize: float) -> None:
        r"""

        Parameters
        ----------
        vlbpsize : float
          the size of the virtual LBP

        """
        return _bn.LoopyWeightedSampling_setVirtualLBPSize(self, vlbpsize)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.LoopyWeightedSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.LoopyWeightedSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.LoopyWeightedSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.LoopyWeightedSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.LoopyWeightedSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyWeightedSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.LoopyWeightedSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.LoopyWeightedSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.LoopyWeightedSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.LoopyWeightedSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.LoopyWeightedSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyWeightedSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.LoopyWeightedSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.LoopyWeightedSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.LoopyWeightedSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.LoopyWeightedSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.LoopyWeightedSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LoopyWeightedSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyWeightedSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LoopyWeightedSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyWeightedSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LoopyWeightedSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LoopyWeightedSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LoopyWeightedSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LoopyWeightedSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LoopyWeightedSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LoopyWeightedSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyWeightedSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyWeightedSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LoopyWeightedSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LoopyWeightedSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LoopyWeightedSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyWeightedSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LoopyWeightedSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LoopyWeightedSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LoopyWeightedSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LoopyWeightedSampling_evidenceImpact(self, *args)

# Register LoopyWeightedSampling in _bn:
_bn.LoopyWeightedSampling_swigregister(LoopyWeightedSampling)
class LoopyGibbsSampling(GibbsSampling):
    r"""

    Class used for inferences using a loopy version of importance sampling.

    LoopyImportanceSampling(bn) -> LoopyImportanceSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.LoopyGibbsSampling_swiginit(self, _bn.new_LoopyGibbsSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_LoopyGibbsSampling

    def makeInference_(self) -> None:
        return _bn.LoopyGibbsSampling_makeInference_(self)

    def setVirtualLBPSize(self, vlbpsize: float) -> None:
        r"""

        Parameters
        ----------
        vlbpsize : float
          the size of the virtual LBP

        """
        return _bn.LoopyGibbsSampling_setVirtualLBPSize(self, vlbpsize)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.LoopyGibbsSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.LoopyGibbsSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.LoopyGibbsSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.LoopyGibbsSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.LoopyGibbsSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyGibbsSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.LoopyGibbsSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.LoopyGibbsSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.LoopyGibbsSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.LoopyGibbsSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.LoopyGibbsSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyGibbsSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.LoopyGibbsSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.LoopyGibbsSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.LoopyGibbsSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.LoopyGibbsSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.LoopyGibbsSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LoopyGibbsSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyGibbsSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LoopyGibbsSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyGibbsSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LoopyGibbsSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LoopyGibbsSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LoopyGibbsSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LoopyGibbsSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LoopyGibbsSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LoopyGibbsSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyGibbsSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyGibbsSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LoopyGibbsSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LoopyGibbsSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LoopyGibbsSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyGibbsSampling_currentPosterior(self, *args)

    def nbrDrawnVar(self) -> int:
        r"""

        Returns
        -------
        int
          the number of variable drawn at each iteration

        """
        return _bn.LoopyGibbsSampling_nbrDrawnVar(self)

    def setNbrDrawnVar(self, _nbr: int) -> None:
        r"""

        Parameters
        ----------
        _nbr : int
          the number of variables to be drawn at each iteration

        """
        return _bn.LoopyGibbsSampling_setNbrDrawnVar(self, _nbr)

    def isDrawnAtRandom(self) -> bool:
        r"""

        Returns
        -------
        bool
          True if variables are drawn at random

        """
        return _bn.LoopyGibbsSampling_isDrawnAtRandom(self)

    def setDrawnAtRandom(self, _atRandom: bool) -> None:
        r"""

        Parameters
        ----------
        _atRandom : bool
          indicates if variables should be drawn at random

        """
        return _bn.LoopyGibbsSampling_setDrawnAtRandom(self, _atRandom)

    def burnIn(self) -> int:
        r"""

        Returns
        -------
        int
          size of burn in on number of iteration

        """
        return _bn.LoopyGibbsSampling_burnIn(self)

    def setBurnIn(self, b: int) -> None:
        r"""

        Parameters
        ----------
        b : int
          size of burn in on number of iteration

        """
        return _bn.LoopyGibbsSampling_setBurnIn(self, b)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LoopyGibbsSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LoopyGibbsSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LoopyGibbsSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LoopyGibbsSampling_evidenceImpact(self, *args)

# Register LoopyGibbsSampling in _bn:
_bn.LoopyGibbsSampling_swigregister(LoopyGibbsSampling)
class LoopyMonteCarloSampling(MonteCarloSampling):
    r"""

    Class used for inferences using a loopy version of importance sampling.

    LoopyImportanceSampling(bn) -> LoopyImportanceSampling
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.LoopyMonteCarloSampling_swiginit(self, _bn.new_LoopyMonteCarloSampling(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_LoopyMonteCarloSampling

    def makeInference_(self) -> None:
        return _bn.LoopyMonteCarloSampling_makeInference_(self)

    def setVirtualLBPSize(self, vlbpsize: float) -> None:
        r"""

        Parameters
        ----------
        vlbpsize : float
          the size of the virtual LBP

        """
        return _bn.LoopyMonteCarloSampling_setVirtualLBPSize(self, vlbpsize)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.LoopyMonteCarloSampling_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.LoopyMonteCarloSampling_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.LoopyMonteCarloSampling_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.LoopyMonteCarloSampling_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.LoopyMonteCarloSampling_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyMonteCarloSampling_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.LoopyMonteCarloSampling_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.LoopyMonteCarloSampling_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.LoopyMonteCarloSampling_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.LoopyMonteCarloSampling_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.LoopyMonteCarloSampling_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyMonteCarloSampling_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.LoopyMonteCarloSampling_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.LoopyMonteCarloSampling_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.LoopyMonteCarloSampling_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.LoopyMonteCarloSampling_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.LoopyMonteCarloSampling__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LoopyMonteCarloSampling_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyMonteCarloSampling_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LoopyMonteCarloSampling_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LoopyMonteCarloSampling_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LoopyMonteCarloSampling_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LoopyMonteCarloSampling_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyMonteCarloSampling_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LoopyMonteCarloSampling_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LoopyMonteCarloSampling_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LoopyMonteCarloSampling_BN(self)

    def currentPosterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the current posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the current posterior probability of the node

        Raises
        ------
        UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyMonteCarloSampling_currentPosterior(self, *args)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LoopyMonteCarloSampling_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LoopyMonteCarloSampling_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LoopyMonteCarloSampling_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LoopyMonteCarloSampling_evidenceImpact(self, *args)

# Register LoopyMonteCarloSampling in _bn:
_bn.LoopyMonteCarloSampling_swigregister(LoopyMonteCarloSampling)
class LoopyBeliefPropagation(object):
    r"""

    Class used for inferences using loopy belief propagation algorithm.

    LoopyBeliefPropagation(bn) -> LoopyBeliefPropagation
        Parameters:
            - **bn** (*pyagrum.BayesNet*) -- a Bayesian network

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "IBayesNet"):
        _bn.LoopyBeliefPropagation_swiginit(self, _bn.new_LoopyBeliefPropagation(bn))

        self._model=bn#BN



    __swig_destroy__ = _bn.delete_LoopyBeliefPropagation

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.LoopyBeliefPropagation_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.LoopyBeliefPropagation_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.LoopyBeliefPropagation_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.LoopyBeliefPropagation_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.LoopyBeliefPropagation_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyBeliefPropagation_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.LoopyBeliefPropagation_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.LoopyBeliefPropagation_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.LoopyBeliefPropagation_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.LoopyBeliefPropagation_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.LoopyBeliefPropagation_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.LoopyBeliefPropagation_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.LoopyBeliefPropagation_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.LoopyBeliefPropagation_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.LoopyBeliefPropagation_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.LoopyBeliefPropagation_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.LoopyBeliefPropagation__asIApproximationSchemeConfiguration(self)

    def makeInference(self) -> None:
        r"""

        Perform the heavy computations needed to compute the targets' posteriors

        In a Junction tree propagation scheme, for instance, the heavy computations are those of the messages sent in the JT.
        This is precisely what makeInference should compute. Later, the computations of the posteriors can be done 'lightly' by multiplying and projecting those messages.

        """
        return _bn.LoopyBeliefPropagation_makeInference(self)

    def posterior(self, *args) -> "pyagrum.Tensor":
        r"""

        Computes and returns the posterior of a node.

        Parameters
        ----------
        var : int
          the node Id of the node for which we need a posterior probability
        nodeName : str
          the node name of the node for which we need a posterior probability

        Returns
        -------
        pyagrum.Tensor
          a const ref to the posterior probability of the node

        Raises
        ------
        pyagrum.UndefinedElement
          If an element of nodes is not in targets

        """
        return _bn.LoopyBeliefPropagation_posterior(self, *args)

    def addEvidence(self, *args) -> None:
        r"""

        Adds a new evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val :
          (int) a node value
        val :
          (str) the label of the node value
        vals : list
          a list of values

        Raises
        ------
          pyagrum.InvalidArgument
            If the node already has an evidence
          pyagrum.InvalidArgument
            If val is not a value for the node
          pyagrum.InvalidArgument
            If the size of vals is different from the domain side of the node
          pyagrum.FatalError
            If vals is a vector of 0s
          pyagrum.UndefinedElement
            If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_addEvidence(self, *args)

    def chgEvidence(self, *args) -> None:
        r"""

        Change the value of an already existing evidence on a node (might be soft or hard).

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name
        val : intstr
          a node value or the label of the node value
        vals : List[float]
          a list of values

        Raises
        ------
        pyagrum.InvalidArgument
          If the node does not already have an evidence
        pyagrum.InvalidArgument
          If val is not a value for the node
        pyagrum.InvalidArgument
          If the size of vals is different from the domain side of the node
        pyagrum.FatalError
          If vals is a vector of 0s
        pyagrum.UndefinedElement
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_chgEvidence(self, *args)

    def hasEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if some node(s) (or the one in parameters) have received evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_hasEvidence(self, *args)

    def eraseAllEvidence(self) -> None:
        r"""

        Removes all the evidence entered into the network.

        """
        return _bn.LoopyBeliefPropagation_eraseAllEvidence(self)

    def eraseEvidence(self, *args) -> None:
        r"""

        Remove the evidence, if any, corresponding to the node Id or name.

        Parameters
        ----------
        id : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_eraseEvidence(self, *args)

    def hasHardEvidence(self, nodeName: str) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a hard evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_hasHardEvidence(self, nodeName)

    def hasSoftEvidence(self, *args) -> bool:
        r"""

        Parameters
        ----------
        id : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if node has received a soft evidence

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_hasSoftEvidence(self, *args)

    def nbrEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of evidence entered into the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_nbrEvidence(self)

    def nbrHardEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of hard evidence entered into the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_nbrHardEvidence(self)

    def nbrSoftEvidence(self) -> int:
        r"""

        Returns
        -------
        int
          the number of soft evidence entered into the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_nbrSoftEvidence(self)

    def eraseAllTargets(self) -> None:
        r"""

        Clear all previously defined targets (marginal and joint targets).

        As a result, no posterior can be computed (since we can only compute the posteriors of the marginal or joint targets that have been added by the user).

        """
        return _bn.LoopyBeliefPropagation_eraseAllTargets(self)

    def addAllTargets(self) -> None:
        r"""

        Add all the nodes as targets.

        """
        return _bn.LoopyBeliefPropagation_addAllTargets(self)

    def addTarget(self, *args) -> None:
        r"""

        Add a marginal target to the list of targets.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : str
          a node name

        Raises
        ------
        pyagrum.UndefinedElement
          If target is not a NodeId in the Bayes net

        """
        return _bn.LoopyBeliefPropagation_addTarget(self, *args)

    def eraseTarget(self, *args) -> None:
        r"""

        Remove, if existing, the marginal target.

        Parameters
        ----------
        target : int
          a node Id
        nodeName : int
          a node name

        Raises
        ------
        pyagrum.IndexError
          If one of the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_eraseTarget(self, *args)

    def isTarget(self, *args) -> bool:
        r"""

        Parameters
        ----------
        variable : int
         a node Id
        nodeName : str
          a node name

        Returns
        -------
        bool
          True if variable is a (marginal) target

        Raises
        ------
        pyagrum.IndexError
          If the node does not belong to the Bayesian network
        pyagrum.UndefinedElement
          If node Id is not in the Bayesian network

        """
        return _bn.LoopyBeliefPropagation_isTarget(self, *args)

    def nbrTargets(self) -> int:
        r"""

        Returns
        -------
        int
          the number of marginal targets

        """
        return _bn.LoopyBeliefPropagation_nbrTargets(self)

    def H(self, *args) -> float:
        r"""

        Parameters
        ----------
        X : int
          a node Id
        nodeName : str
          a node name

        Returns
        -------
        float
          the computed Shanon's entropy of a node given the observation

        """
        return _bn.LoopyBeliefPropagation_H(self, *args)

    def BN(self) -> "pyagrum.IBayesNet":
        r"""

        Returns
        -------
        pyagrum.IBayesNet
          A constant reference over the IBayesNet referenced by this class.

        Raises
        ------
          pyagrum.UndefinedElement
            If no Bayes net has been assigned to the inference.

        """
        return _bn.LoopyBeliefPropagation_BN(self)

    def setEvidence(self, evidces):
        """
        Erase all the evidences and apply addEvidence(key,value) for every pairs in evidces.

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
        pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          self.eraseAllEvidence()
          for k,v in evidces.items():
            self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          self.eraseAllEvidence()
          for p in evidces:
            self.addEvidence(p)
          return
        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def updateEvidence(self, evidces):
        """
        Apply chgEvidence(key,value) for every pairs in evidces (or addEvidence).

        Parameters
        ----------
        evidces : Dict[str,Union[int,str,List[float]]] or List[pyagrum.Tensor]
          a dict of "name:evidence" where name is a string (the name of the variable) and evidence is an integer (an index) or a string (a label) or a list of float (a likelihood).

        Raises
        ------
          pyagrum.InvalidArgument
            If one value is not a value for the node
          pyagrum.InvalidArgument
            If the size of a value is different from the domain side of the node
          pyagrum.FatalError
            If one value is a vector of 0s
          pyagrum.UndefinedElement
            If one node does not belong to the Bayesian network
        """
        if isinstance(evidces, dict):
          for k,v in evidces.items():
              if self.hasEvidence(k):
                  self.chgEvidence(k,v)
              else:
                  self.addEvidence(k,v)
          return
        elif isinstance(evidces, list):#should be a list of Tensor
          for p in evidces:
              k=p.variable(0)
              if self.hasEvidence(k):
                  self.chgEvidence(p)
              else:
                  self.addEvidence(p)
          return

        raise TypeError("Parameter must be a dict or a list, not %s"%(type(evidces)))



    def setTargets(self, targets):
        """
        Remove all the targets and add the ones in parameter.

        Parameters
        ----------
        targets : set
          a set of targets

        Raises
        ------
          pyagrum.UndefinedElement
            If one target is not in the Bayes net
        """
        if not isinstance(targets, set):
            raise TypeError("setTargets parameter must be a set, not %s"%(type(targets)))

        self.eraseAllTargets()
        for k in targets:
            self.addTarget(k)



    def hardEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with hard evidence

        """
        return _bn.LoopyBeliefPropagation_hardEvidenceNodes(self)

    def softEvidenceNodes(self) -> object:
        r"""

        Returns
        -------
        set
          the set of nodes with soft evidence

        """
        return _bn.LoopyBeliefPropagation_softEvidenceNodes(self)

    def targets(self) -> object:
        r"""

        Returns
        -------
        list
          the list of marginal targets

        """
        return _bn.LoopyBeliefPropagation_targets(self)

    def evidenceImpact(self, *args) -> "pyagrum.Tensor":
        r"""

        Create a pyagrum.Tensor for P(target|evs) (for all instanciation of target and evs)

        Parameters
        ----------
        target : set
          a set of targets ids or names.
        evs : set
          a set of nodes ids or names.

        Warnings
        --------
        if some evs are d-separated, they are not included in the Tensor.

        Returns
        -------
        pyagrum.Tensor
          a Tensor for P(targets|evs)

        """
        return _bn.LoopyBeliefPropagation_evidenceImpact(self, *args)

# Register LoopyBeliefPropagation in _bn:
_bn.LoopyBeliefPropagation_swigregister(LoopyBeliefPropagation)
class ExactBNdistance(object):
    r"""

    Class representing exacte computation of divergence and distance between BNs

    ExactBNdistance(P,Q) -> ExactBNdistance
        Parameters:
            - **P** (*pyagrum.BayesNet*)
              a Bayesian network
            - **Q** (*pyagrum.BayesNet*)
              another Bayesian network to compare with the first one

    ExactBNdistance(ebnd) -> ExactBNdistance
        Parameters:
            - **ebnd** (*pyagrum.ExactBNdistance*)
              the exact BNdistance to copy

    Raises
    ------
      pyagrum.OperationNotAllowed
    	If the 2BNs have not the same domain size of compatible node sets

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.ExactBNdistance_swiginit(self, _bn.new_ExactBNdistance(*args))
    __swig_destroy__ = _bn.delete_ExactBNdistance

    def compute(self) -> object:
        r"""

        Returns
        -------
        Dict[str,float]
        	a dictionnary containing the different values after the computation.

        """
        return _bn.ExactBNdistance_compute(self)

# Register ExactBNdistance in _bn:
_bn.ExactBNdistance_swigregister(ExactBNdistance)
class GibbsBNdistance(pyagrum.base.ApproximationScheme):
    r"""

    Class representing a Gibbs-Approximated computation of divergence and distance between BNs


    GibbsBNdistance(P,Q) -> GibbsBNdistance
        Parameters:
            - **P** (*pyagrum.BayesNet*) -- a Bayesian network
            - **Q** (*pyagrum.BayesNet*) -- another Bayesian network to compare with the first one

    GibbsBNdistance(gbnd) -> GibbsBNdistance
        Parameters:
            - **gbnd** (*pyagrum.GibbsBNdistance*) -- the Gibbs BNdistance to copy

    Raises
    ------
      pyagrum.OperationNotAllowed
    	If the 2BNs have not the same domain size of compatible node sets

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, *args):
        _bn.GibbsBNdistance_swiginit(self, _bn.new_GibbsBNdistance(*args))
    __swig_destroy__ = _bn.delete_GibbsBNdistance

    def setBurnIn(self, b: int) -> None:
        r"""

        Parameters
        ----------
        b : int
        	size of burn in on number of iteration

        """
        return _bn.GibbsBNdistance_setBurnIn(self, b)

    def burnIn(self) -> int:
        r"""

        Returns
        -------
        int
        	size of burn in on number of iteration

        """
        return _bn.GibbsBNdistance_burnIn(self)

    def compute(self) -> object:
        r"""

        Returns
        -------
        Dict[str,float]
        	a dictionnary containing the different values after the computation.

        """
        return _bn.GibbsBNdistance_compute(self)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.GibbsBNdistance_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.GibbsBNdistance_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.GibbsBNdistance_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.GibbsBNdistance_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.GibbsBNdistance_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.GibbsBNdistance_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.GibbsBNdistance_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.GibbsBNdistance_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.GibbsBNdistance_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.GibbsBNdistance_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.GibbsBNdistance_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.GibbsBNdistance_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.GibbsBNdistance_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.GibbsBNdistance_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.GibbsBNdistance_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.GibbsBNdistance_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.GibbsBNdistance__asIApproximationSchemeConfiguration(self)

    def nbrDrawnVar(self) -> int:
        r"""

        Returns
        -------
        int
          the number of variable drawn at each iteration

        """
        return _bn.GibbsBNdistance_nbrDrawnVar(self)

    def setNbrDrawnVar(self, _nbr: int) -> None:
        r"""

        Parameters
        ----------
        _nbr : int
          the number of variables to be drawn at each iteration

        """
        return _bn.GibbsBNdistance_setNbrDrawnVar(self, _nbr)

    def isDrawnAtRandom(self) -> bool:
        r"""

        Returns
        -------
        bool
          True if variables are drawn at random

        """
        return _bn.GibbsBNdistance_isDrawnAtRandom(self)

    def setDrawnAtRandom(self, _atRandom: bool) -> None:
        r"""

        Parameters
        ----------
        _atRandom : bool
          indicates if variables should be drawn at random

        """
        return _bn.GibbsBNdistance_setDrawnAtRandom(self, _atRandom)

# Register GibbsBNdistance in _bn:
_bn.GibbsBNdistance_swigregister(GibbsBNdistance)
class BNDatabaseGenerator(object):
    r"""

    BNDatabaseGenerator is used to easily generate databases from a pyagrum.BayesNet.

    Parameters
    ----------
    bn: pyagrum.BayesNet
      the Bayesian network used to generate data.

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")
    __repr__ = _swig_repr

    def __init__(self, bn: "pyagrum.BayesNet"):
        _bn.BNDatabaseGenerator_swiginit(self, _bn.new_BNDatabaseGenerator(bn))
    __swig_destroy__ = _bn.delete_BNDatabaseGenerator

    def setDiscretizedLabelModeRandom(self) -> None:
        r"""

        Set the discretized label mode to RANDOM (default mode) : sampling a `pyagrum.discretizedVariable` will give a random value from the uniform distribution on that interval.

        Examples
        --------
        >>> import pyagrum as gum
        >>> bn=pyagrum.fastBN('A->B{yes|maybe|no}<-C->D->E<-F[1,1.5,3,10.2]<-B')
        >>> g=pyagrum.BNDatabaseGenerator(bn)
        >>> g.setRandomVarOrder()
        >>> g.drawSamples(5,
        ...               {'B':'yes','E':'1'})
        -122.98754206579288
        >>> g.setDiscretizedLabelModeRandom() # By default
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes  2.802302  0  0  1  0
        1  yes  1.761605  0  0  1  0
        2  yes  2.507535  0  0  1  1
        3  yes  2.815282  0  1  1  0
        4  yes  5.548571  1  0  1  1

        """
        return _bn.BNDatabaseGenerator_setDiscretizedLabelModeRandom(self)

    def setDiscretizedLabelModeMedian(self) -> None:
        r"""

        Set the discretized label mode to MEDIAN : sampling a `pyagrum.discretizedVariable` will give a deterministic value : the median of the uniform distribution on that interval.

        Examples
        --------
        >>> import pyagrum as gum
        >>> bn=pyagrum.fastBN('A->B{yes|maybe|no}<-C->D->E<-F[1,1.5,3,10.2]<-B')
        >>> g=pyagrum.BNDatabaseGenerator(bn)
        >>> g.setRandomVarOrder()
        >>> g.drawSamples(5,
        ...               {'B':'yes','E':'1'})
        -122.98754206579288
        >>> g.setDiscretizedLabelModeMedian()
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes  2.250000  0  0  1  0
        1  yes  2.250000  0  0  1  0
        2  yes  2.250000  0  0  1  1
        3  yes  2.250000  0  1  1  0
        4  yes  6.600000  1  0  1  1

        """
        return _bn.BNDatabaseGenerator_setDiscretizedLabelModeMedian(self)

    def setDiscretizedLabelModeInterval(self) -> None:
        r"""

        Set the discretized label mode to INTERVAL : sampling a `pyagrum.discretizedVariable` will give a deterministic value : the string representation of the interval.

        Examples
        --------
        >>> import pyagrum as gum
        >>> bn=pyagrum.fastBN('A->B{yes|maybe|no}<-C->D->E<-F[1,1.5,3,10.2]<-B')
        >>> g=pyagrum.BNDatabaseGenerator(bn)
        >>> g.setRandomVarOrder()
        >>> g.drawSamples(5,
        ...               {'B':'yes','E':'1'})
        -122.98754206579288
        >>> g.setDiscretizedLabelModeInterval()
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes   [1.5;3[  0  0  1  0
        1  yes   [1.5;3[  0  0  1  0
        2  yes   [1.5;3[  0  0  1  1
        3  yes   [1.5;3[  0  1  1  0
        4  yes  [3;10.2]  1  0  1  1

        """
        return _bn.BNDatabaseGenerator_setDiscretizedLabelModeInterval(self)

    def toCSV(self, *args) -> None:
        r"""

        generates csv representing the generated database.

        Parameters
        ----------
        csvFilename: str
          the name of the csv file
        useLabels: bool
          whether label or id in the csv file (default true)
        append: bool
          append in the file or rewrite the file (default false)
        csvSeparator: str
          separator in the csv file (default ',')

        """
        return _bn.BNDatabaseGenerator_toCSV(self, *args)

    def samplesNbRows(self) -> int:
        r"""

        return the number of rows in the samples

        """
        return _bn.BNDatabaseGenerator_samplesNbRows(self)

    def samplesNbCols(self) -> int:
        r"""

        return the number of columns in the samples

        """
        return _bn.BNDatabaseGenerator_samplesNbCols(self)

    def samplesAt(self, row: int, col: int) -> int:
        r"""

        Get the value of the database in (row,col)

        Parameters
        ----------
        row : int
          the row
        col : int
          the column (using the ordered list of variables)

        Returns
        -------
        int
          the index of the modality of the variable in this position

        """
        return _bn.BNDatabaseGenerator_samplesAt(self, row, col)

    def samplesLabelAt(self, row: int, col: int) -> str:
        r"""

        Get the label of the database in (row,col)

        Parameters
        ----------
        row : int
          the row
        col : int
          the column (using the ordered list of variables)

        Returns
        -------
        str
          the label of the modality of the variable in this position

        """
        return _bn.BNDatabaseGenerator_samplesLabelAt(self, row, col)

    def setVarOrder(self, *args) -> None:
        r"""

        Set a specific order with a list of names

        Parameters
        ----------
        vars : List[str]
          order specified by the list of variable names.

        """
        return _bn.BNDatabaseGenerator_setVarOrder(self, *args)

    def setVarOrderFromCSV(self, *args) -> None:
        r"""

        Set the same order than in a csv file

        Parameters
        ----------
        filename:str
          the name of the CSV file

        """
        return _bn.BNDatabaseGenerator_setVarOrderFromCSV(self, *args)

    def setTopologicalVarOrder(self) -> None:
        r"""

        Select a topological order for the variables in the database.

        """
        return _bn.BNDatabaseGenerator_setTopologicalVarOrder(self)

    def setAntiTopologicalVarOrder(self) -> None:
        r"""

        Select an anti-topological order for the variables in the database.

        """
        return _bn.BNDatabaseGenerator_setAntiTopologicalVarOrder(self)

    def setRandomVarOrder(self) -> None:
        r"""

        Select an random order for the variables in the database.

        """
        return _bn.BNDatabaseGenerator_setRandomVarOrder(self)

    def varOrderNames(self) -> List[str]:
        r"""

        The actual order for the variable (as a tuple of NodeId)

        Returns
        -------
        Tuple[str]
          the tuple of names

        """
        return _bn.BNDatabaseGenerator_varOrderNames(self)

    def log2likelihood(self) -> float:
        r"""

        Get the  log2likelihood of the generated database

        Raises
        ------
        pyagrum.OperationNotAllowed
          if nothing has been sampled yet (using `pyagrum.BNDatabaseGenerator.drawSamples()` for instance)

        Returns
        -------
        float
          the log2likelihood

        """
        return _bn.BNDatabaseGenerator_log2likelihood(self)

    def bn(self) -> "pyagrum.BayesNet":
        r"""

        Get the Bayesian network used to generate the samples

        Returns
        -------
        pyagrum.BayesNet
          The Bayesian network


        """
        return _bn.BNDatabaseGenerator_bn(self)

    def varOrder(self) -> object:
        r"""

        The actual order for the variable (as a tuple of NodeId)

        Returns
        -------
        Tuple[int]
          the tuple of NodeId

        """
        return _bn.BNDatabaseGenerator_varOrder(self)

    def drawSamples(self, *args) -> float:
        r"""

        Generate and stock a database generated by sampling the Bayesian network.

        If `evs` is specified, the samples are stored only if there are compatible with these observations.

        Returns the log2likelihood of this database.

        Parameters
        ----------
        nbSamples : int
        	the number of samples that will be generated
        evs : "pyagrum.Instantiation" or Dict[intstr,intstr]
          (optional) The evidence that will be observed by the resulting samples.
        timeout : int
          (optional) The maximum time in seconds to generate the samples (default 600)

        Warning
        -------
        `nbSamples` is not the number of generated samples but the size of the database.It may happen that the evidence is very rare (or even impossible). In this case, the generation process may be *very* slow (it may even not stop). For this case a timeout is provided (default 600 seconds) and then the size of the database can be smaller than `nbSamples` (even equal to 0).

        Warning
        -------
        For discretized variable, aGrum/pyAgrum defines 3 behaviors when generating sample with labels :
        - RANDOM (default) : the value is chosen randomly in the interval
        - MEDIAN : the value is the median of the interval
        - INTERVAL : the value is the interval itself (for instance ` [0,1[ `)

        The behavior can be set using `setDiscretizedLabelMode{Random|Median|Interval}`.

        Examples
        --------
        >>> import pyagrum as gum
        >>> bn=pyagrum.fastBN('A->B{yes|maybe|no}<-C->D->E<-F[1,1.5,3,10.2]<-B')
        >>> g=pyagrum.BNDatabaseGenerator(bn)
        >>> g.setRandomVarOrder()
        >>> g.drawSamples(5,
        ...               {'B':'yes','E':'1'})
        -122.98754206579288
        >>> g.setDiscretizedLabelModeRandom() # By default
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes  2.802302  0  0  1  0
        1  yes  1.761605  0  0  1  0
        2  yes  2.507535  0  0  1  1
        3  yes  2.815282  0  1  1  0
        4  yes  5.548571  1  0  1  1
        >>> g.setDiscretizedLabelModeMedian()
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes  2.250000  0  0  1  0
        1  yes  2.250000  0  0  1  0
        2  yes  2.250000  0  0  1  1
        3  yes  2.250000  0  1  1  0
        4  yes  6.600000  1  0  1  1
        >>> g.setDiscretizedLabelModeInterval()
        >>> g.to_pandas()
             B         F  A  C  E  D
        0  yes   [1.5;3[  0  0  1  0
        1  yes   [1.5;3[  0  0  1  0
        2  yes   [1.5;3[  0  0  1  1
        3  yes   [1.5;3[  0  1  1  0
        4  yes  [3;10.2]  1  0  1  1

        """
        return _bn.BNDatabaseGenerator_drawSamples(self, *args)

    def to_pandas(self,with_labels=True):
      r"""
      export the samples as a pandas.DataFrame.

      Parameters
      ----------
      with_labels: bool
        is the DataFrame full of labels of variables or full of index of labels of variables
      """
      import pandas

      nrow=self.samplesNbRows()
      ncol=self.samplesNbCols()

      if with_labels:
        ldatas=[[self.samplesLabelAt(row,col) for col in range(ncol)] for row in range(nrow)]
      else:
        ldatas=[[self.samplesAt(row,col) for col in range(ncol)] for row in range(nrow)]

      return pandas.DataFrame(columns=self.varOrderNames(),data=ldatas)


# Register BNDatabaseGenerator in _bn:
_bn.BNDatabaseGenerator_swigregister(BNDatabaseGenerator)
class BNLearner(object):
    r"""

    This class provides functionality for learning Bayesian Networks from data.

    BNLearner(filename,inducedTypes=True) -> BNLearner
        Parameters:
            - **source** (*str* or *pandas.DataFrame*) -- the data to learn from
            - **missingSymbols** (*List[str]*) -- list of strings that will be interpreted as missing values (by default : `?`)
            - **inducedTypes** (*Bool*) -- whether BNLearner should try to automatically find the type of each variable

    BNLearner(filename,src) -> BNLearner
        Parameters:
            - **source** (*str* or *pandas.DataFrame*) -- the data to learn from
            - **src** (*pyagrum.BayesNet*) -- the Bayesian network used to find those modalities
            - **missingSymbols** (*List[str]*) -- list of strings that will be interpreted as missing values (by default : `?`)

    BNLearner(learner) -> BNLearner
        Parameters:
            - **learner** (*pyagrum.BNLearner*) -- the BNLearner to copy

    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args):

        if type(args[0]) is not str:
          if hasattr(args[0],"to_csv") or hasattr(args[0],"write_csv"):
              import tempfile
              csvfile = tempfile.NamedTemporaryFile(delete=False)
              tmpfilename = csvfile.name
              csvfilename = tmpfilename + ".csv"
              csvfile.close()

              if hasattr(args[0],"to_csv"):
                args[0].to_csv(csvfilename,na_rep="?",index=False)
              else:
                args[0].write_csv(csvfilename,null_value="?")

              self.__init__(csvfilename,*args[1:])
              return
          else:
            raise TypeError("first argument must be a string or a DataFrame")


        _bn.BNLearner_swiginit(self, _bn.new_BNLearner(*args))
    __swig_destroy__ = _bn.delete_BNLearner

    def learnBN(self) -> "pyagrum.BayesNet":
        r"""

        learn a BayesNet from a file (must have read the db before)

        Returns
        -------
        pyagrum.BayesNet
        	the learned BayesNet

        """
        return _bn.BNLearner_learnBN(self)

    def learnParameters(self, *args) -> "pyagrum.BayesNet":
        r"""

        Create a new BN copying its structure from the argument (dag or BN) and learning its parameters from the database w.r.t the BNLearner's state (priors, etc.).

        Warnings
        --------
        When using a `pyagrum.DAG` as input parameter, NodeIds in the dag and index of rows in the database must fit in order to coherently fix the structure of the BN.
        Generally, it is safer to use a `pyagrum.BayesianNet` as input or even to use `pyagrum.BNLearner.fitParameters`.

        Parameters
        ----------
        dag : pyagrum.DAG
        bn : pyagrum.BayesNet
        take_into_account_score : bool
        	The dag passed in argument may have been learnt from a structure learning. In this case, if the score used to learn the structure has an implicit prior (like K2 which has a 1-smoothing prior), it is important to also take into account this implicit prior for parameter learning. By default (`take_into_account_score=True`), we will learn parameters by taking into account the prior specified by methods usePriorXXX () + the implicit prior of the score (if any). If `take_into_account_score=False`, we just take into account the prior specified by `usePriorXXX()`.

        Returns
        -------
        pyagrum.BayesNet
        	the learned BayesNet

        Raises
        ------
        pyagrum.MissingVariableInDatabase
        	If a variable of the BN is not found in the database
        pyagrum.UnknownLabelInDatabase
        	If a label is found in the database that do not correspond to the variable

        """

        if type(args[0])==pyagrum.BayesNet:
            res=pyagrum.BayesNet(args[0])
            self.fitParameters(res)
            return res



        return _bn.BNLearner_learnParameters(self, *args)


    def copyState(self, learner: "BNLearner") -> None:
        r"""

        Copy the state of the given pyagrum.BNLearner (as argument).

        Parameters
        ----------
        pyagrum.BNLearner
            the learner whose state is copied.

        """
        val = _bn.BNLearner_copyState(self, learner)

        return self


        return val


    def setInitialDAG(self, dag: "pyagrum.DAG") -> "pyagrum.BNLearner":
        r"""

        Parameters
        ----------
        dag : pyagrum.DAG
        	an initial pyagrum.DAG structure

        """
        return _bn.BNLearner_setInitialDAG(self, dag)

    def useEM(self, epsilon: float) -> "pyagrum.BNLearner":
        r"""

        Indicates if we use EM for parameter learning.

        Parameters
        ----------
        epsilon : float
        	if epsilon=0.0 then EM is not used.
        	if epsilon>0 then EM is used and stops when the sum of the cumulative squared error on parameters is less than epsilon.

        """
        return _bn.BNLearner_useEM(self, epsilon)

    def useScoreAIC(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use an AIC score.

        """
        return _bn.BNLearner_useScoreAIC(self)

    def useScoreBD(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a BD score.

        """
        return _bn.BNLearner_useScoreBD(self)

    def useScoreBDeu(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a BDeu score.

        """
        return _bn.BNLearner_useScoreBDeu(self)

    def useScoreBIC(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a BIC score.

        """
        return _bn.BNLearner_useScoreBIC(self)

    def useScoreK2(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a K2 score.

        """
        return _bn.BNLearner_useScoreK2(self)

    def useScoreLog2Likelihood(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a Log2Likelihood score.

        """
        return _bn.BNLearner_useScoreLog2Likelihood(self)

    def useNoPrior(self) -> "pyagrum.BNLearner":
        r"""

        Use no prior.

        """
        return _bn.BNLearner_useNoPrior(self)

    def useBDeuPrior(self, weight: float=1.0) -> "pyagrum.BNLearner":
        r"""

        The BDeu prior adds weight to all the cells of the counting tables.
        In other words, it adds weight rows in the database with equally probable
        values.

        Parameters
        ----------
        weight : float
        	the prior weight

        """
        return _bn.BNLearner_useBDeuPrior(self, weight)

    def useSmoothingPrior(self, weight: float=1) -> "pyagrum.BNLearner":
        r"""

        Use the prior smoothing.

        Parameters
        ----------
        weight : float
                pass in argument a weight if you wish to assign a weight to the smoothing, otherwise the current weight of the learner will be used.

        """
        return _bn.BNLearner_useSmoothingPrior(self, weight)

    def useDirichletPrior(self, *args) -> "pyagrum.BNLearner":
        r"""

        Use the Dirichlet prior.

        Parameters
        ----------
        source : str|pyagrum.BayesNet
                the Dirichlet related source (filename of a database or a Bayesian network)
        weight : float (optional)
                the weight of the prior (the 'size' of the corresponding 'virtual database')

        """
        return _bn.BNLearner_useDirichletPrior(self, *args)

    def useGreedyHillClimbing(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a greedy hill climbing algorithm.

        """
        return _bn.BNLearner_useGreedyHillClimbing(self)

    def useLocalSearchWithTabuList(self, tabu_size: int=100, nb_decrease: int=2) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use a local search with tabu list

        Parameters
        ----------
        tabu_size : int
                The size of the tabu list

        nb_decrease : int
                The max number of changes decreasing the score consecutively that we allow to apply

        """
        return _bn.BNLearner_useLocalSearchWithTabuList(self, tabu_size, nb_decrease)

    def useMIIC(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use MIIC.

        """
        return _bn.BNLearner_useMIIC(self)

    def useNMLCorrection(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use the NML correction for MIIC

        """
        return _bn.BNLearner_useNMLCorrection(self)

    def useMDLCorrection(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use the MDL correction for MIIC

        """
        return _bn.BNLearner_useMDLCorrection(self)

    def useNoCorrection(self) -> "pyagrum.BNLearner":
        r"""

        Indicate that we wish to use the NoCorr correction for MIIC

        """
        return _bn.BNLearner_useNoCorrection(self)

    def setMaxIndegree(self, max_indegree: int) -> "pyagrum.BNLearner":
        r"""

        Parameters
        ----------
        max_indegree : int
        	the limit number of parents

        """
        return _bn.BNLearner_setMaxIndegree(self, max_indegree)

    def addForbiddenArc(self, *args) -> "pyagrum.BNLearner":
        r"""

        The arc in parameters won't be added.

        Parameters
        ----------
        arc : pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        """
        return _bn.BNLearner_addForbiddenArc(self, *args)

    def eraseForbiddenArc(self, *args) -> "pyagrum.BNLearner":
        r"""

        Allow the arc to be added if necessary.

        Parameters
        ----------
        arc: pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        """
        return _bn.BNLearner_eraseForbiddenArc(self, *args)

    def addMandatoryArc(self, *args) -> "pyagrum.BNLearner":
        r"""

        Allow to add prior structural knowledge.

        Parameters
        ----------
        arc : pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        Raises
        ------
        pyagrum.InvalidDirectedCycle
        	If the added arc creates a directed cycle in the DAG

        """
        return _bn.BNLearner_addMandatoryArc(self, *args)

    def eraseMandatoryArc(self, *args) -> "pyagrum.BNLearner":
        r"""

        Parameters
        ----------
        arc: pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        """
        return _bn.BNLearner_eraseMandatoryArc(self, *args)

    def addPossibleEdge(self, *args) -> "pyagrum.BNLearner":
        r"""

        assign a new possible edge

        Warnings
        --------
          By default, all edge is possible. However, once at least one possible edge is defined, all other edges not declared possible
          are considered as impossible.

        Parameters
        ----------
        arc : pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        """
        return _bn.BNLearner_addPossibleEdge(self, *args)

    def erasePossibleEdge(self, *args) -> "pyagrum.BNLearner":
        r"""

        Allow the 2 arcs to be added if necessary.

        Parameters
        ----------
        arc : pyagrum.Arc
        	an arc
        head : int str
        	a variable's id or name
        tail : int str
        	a variable's id or name

        """
        return _bn.BNLearner_erasePossibleEdge(self, *args)

    def setPossibleSkeleton(self, skeleton: "pyagrum.UndiGraph") -> "pyagrum.BNLearner":
        r"""

        Add a constraint by fixing the set of possible edges as a pyagrum.UndiGraph.

        Parameters
        ----------
        g : pyagrum.UndiGraph
        	the fixed skeleton

        """
        return _bn.BNLearner_setPossibleSkeleton(self, skeleton)

    def addNoParentNode(self, *args) -> "pyagrum.BNLearner":
        return _bn.BNLearner_addNoParentNode(self, *args)

    def eraseNoParentNode(self, *args) -> "pyagrum.BNLearner":
        return _bn.BNLearner_eraseNoParentNode(self, *args)

    def addNoChildrenNode(self, *args) -> "pyagrum.BNLearner":
        return _bn.BNLearner_addNoChildrenNode(self, *args)

    def eraseNoChildrenNode(self, *args) -> "pyagrum.BNLearner":
        return _bn.BNLearner_eraseNoChildrenNode(self, *args)

    def isConstraintBased(self) -> bool:
        return _bn.BNLearner_isConstraintBased(self)

    def isScoreBased(self) -> bool:
        return _bn.BNLearner_isScoreBased(self)

    def __repr__(self) -> str:
        return _bn.BNLearner___repr__(self)

    def __str__(self) -> str:
        return _bn.BNLearner___str__(self)

    def setVerbosity(self, v: bool) -> None:
        r"""

        Parameters
        ----------
        v : bool
                verbosity

        """
        return _bn.BNLearner_setVerbosity(self, v)

    def setEpsilon(self, eps: float) -> None:
        r"""

        Parameters
        ----------
        eps : float
        	the epsilon we want to use

        Raises
        ------
        pyagrum.OutOfBounds
        	If eps<0

        """
        return _bn.BNLearner_setEpsilon(self, eps)

    def setMinEpsilonRate(self, rate: float) -> None:
        r"""

        Parameters
        ----------
        rate : float
        	the minimal epsilon rate

        """
        return _bn.BNLearner_setMinEpsilonRate(self, rate)

    def setMaxIter(self, max: int) -> None:
        r"""

        Parameters
        ----------
        max : int
        	the maximum number of iteration

        Raises
        ------
        pyagrum.OutOfBounds
        	If max <= 1

        """
        return _bn.BNLearner_setMaxIter(self, max)

    def setMaxTime(self, timeout: float) -> None:
        r"""

        Parameters
        ----------
        tiemout : float
        	stopping criterion on timeout (in seconds)

        Raises
        ------
        pyagrum.OutOfBounds
        	If timeout<=0.0

        """
        return _bn.BNLearner_setMaxTime(self, timeout)

    def setPeriodSize(self, p: int) -> None:
        r"""

        Parameters
        ----------
        p : int
        	number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.BNLearner_setPeriodSize(self, p)

    def verbosity(self) -> bool:
        r"""

        Returns
        -------
        bool
        	True if the verbosity is enabled

        """
        return _bn.BNLearner_verbosity(self)

    def epsilon(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of epsilon

        """
        return _bn.BNLearner_epsilon(self)

    def minEpsilonRate(self) -> float:
        r"""

        Returns
        -------
        float
        	the value of the minimal epsilon rate

        """
        return _bn.BNLearner_minEpsilonRate(self)

    def maxIter(self) -> int:
        r"""

        Returns
        -------
        int
        	the criterion on number of iterations

        """
        return _bn.BNLearner_maxIter(self)

    def maxTime(self) -> float:
        r"""

        Returns
        -------
        float
        	the timeout(in seconds)

        """
        return _bn.BNLearner_maxTime(self)

    def periodSize(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of samples between 2 stopping

        Raises
        ------
        pyagrum.OutOfBounds
        	If p<1

        """
        return _bn.BNLearner_periodSize(self)

    def nbrIterations(self) -> int:
        r"""

        Returns
        -------
        int
        	the number of iterations

        """
        return _bn.BNLearner_nbrIterations(self)

    def currentTime(self) -> float:
        r"""

        Returns
        -------
        float
        	get the current running time in second (float)

        """
        return _bn.BNLearner_currentTime(self)

    def messageApproximationScheme(self) -> str:
        r"""

        Returns
        -------
        str
        	the approximation scheme message

        """
        return _bn.BNLearner_messageApproximationScheme(self)

    def history(self) -> List[float]:
        r"""

        Returns
        -------
        tuple
        	the scheme history

        Raises
        ------
        pyagrum.OperationNotAllowed
        	If the scheme did not performed or if verbosity is set to false

        """
        return _bn.BNLearner_history(self)

    def _asIApproximationSchemeConfiguration(self) -> "pyagrum.YetUnWrapped":
        return _bn.BNLearner__asIApproximationSchemeConfiguration(self)

    def learnDAG(self) -> "pyagrum.DAG":
        r"""

        learn a structure from a file

        Returns
        -------
        pyagrum.DAG
        	the learned DAG

        """
        return _bn.BNLearner_learnDAG(self)

    def learnPDAG(self) -> "pyagrum.PDAG":
        r"""

        learn a PDAG from a file

        Warnings
        --------
          The learning method must be constraint-based (MIIC, etc.) and not score-based (K2, GreedyHillClimbing, etc.)

        Returns
        -------
        pyagrum.PDAG
        	the learned PDAG

        """
        return _bn.BNLearner_learnPDAG(self)

    def names(self) -> List[str]:
        r"""

        Returns
        -------
        Tuple[str]
        	the names of the variables in the database

        """
        return _bn.BNLearner_names(self)

    def idFromName(self, var_name: str) -> int:
        r"""

        Parameters
        ----------
        var_names : str
        	a variable's name

        Returns
        -------
        int
        	the column id corresponding to a variable name

        Raises
        ------
        pyagrum.MissingVariableInDatabase
        	If a variable of the BN is not found in the database.

        """
        return _bn.BNLearner_idFromName(self, var_name)

    def nameFromId(self, id: int) -> str:
        r"""

        Parameters
        ----------
        id
        	a node id

        Returns
        -------
        str
        	the variable's name

        """
        return _bn.BNLearner_nameFromId(self, id)

    def setDatabaseWeight(self, new_weight: float) -> None:
        r"""

        Set the database weight which is given as an equivalent sample size.

        Warnings
        --------
        The same weight is assigned to all the rows of the learning database so that the sum of their
        weights is equal to the value of the parameter `weight`.

        Parameters
        ----------
        weight : float
        	the database weight

        """
        return _bn.BNLearner_setDatabaseWeight(self, new_weight)

    def setRecordWeight(self, i: int, weight: float) -> None:
        r"""

        Set the weight of the ith record

        Parameters
        ----------
        i : int
          the position  of the record in the database
        weight : float
          the weight assigned to this record

        Raises
        ------
        pyagrum.OutOfBounds
          if i is outside the set of indices of the records

        """
        return _bn.BNLearner_setRecordWeight(self, i, weight)

    def databaseWeight(self) -> float:
        r"""

        Get the database weight which is given as an equivalent sample size.

        Returns
        -------
        float
          The weight of the database

        """
        return _bn.BNLearner_databaseWeight(self)

    def recordWeight(self, i: int) -> float:
        r"""

        Get the weight of the ith record

        Parameters
        ----------
        i : int
          the position  of the record in the database

        Raises
        ------
        pyagrum.OutOfBounds
          if i is outside the set of indices of the records

        Returns
        -------
        float
          The weight of the ith record of the database

        """
        return _bn.BNLearner_recordWeight(self, i)

    def hasMissingValues(self) -> bool:
        r"""

        Indicates whether there are missing values in the database.

        Returns
        -------
        bool
            True if there are some missing values in the database.

        """
        return _bn.BNLearner_hasMissingValues(self)

    def logLikelihood(self, *args) -> float:
        r"""

        logLikelihood computes the log-likelihood for the columns in vars, given the columns in the list knowing (optional)


        Parameters
        ----------
        vars: List[str]
        	the name of the columns of interest

        knowing : List[str]
        	the (optional) list of names of conditioning columns

        Returns
        -------
        float
        	the log-likelihood (base 2)

        """
        return _bn.BNLearner_logLikelihood(self, *args)

    def score(self, *args) -> float:
        r"""

        Returns the value of the score currently in use by the BNLearner of a variable given a set of other variables

        Parameters
        ----------
        name1: str
        	the name of the variable at the LHS of the conditioning bar

        knowing : List[str]
        	the list of names of the conditioning variables

        Returns
        -------
        float
        	the value of the score

        """
        return _bn.BNLearner_score(self, *args)

    def mutualInformation(self, *args) -> float:
        r"""

        computes the (log2) mutual information between two columns, given a list of other columns.

        Warnings
        --------
        This function gives the 'raw' mutual information. If you want a version taking into account correction and prior, use
        pyagrum.BNLearner.correctedMutualInformation

        Parameters
        ----------
        name1: str
        	the name of the first column

        name2 : str
        	the name of the second column

        knowing : List[str]
        	the list of names of conditioning columns

        Returns
        -------
        float
          the log2 mutual information

        """
        return _bn.BNLearner_mutualInformation(self, *args)

    def correctedMutualInformation(self, *args) -> float:
        r"""

        computes the mutual information between two columns, given a list of other columns (log2).

        Warnings
        --------
        This function takes into account correction and prior. If you want the 'raw' mutual information, use
        pyagrum.BNLearner.mutualInformation


        Parameters
        ----------
        name1: str
        	the name of the first column

        name2 : str
        	the name of the second column

        knowing : List[str]
        	the list of names of conditioning columns

        Returns
        -------
        Tuple[float,float]
        	the G2 statistic and the associated p-value as a Tuple

        """
        return _bn.BNLearner_correctedMutualInformation(self, *args)

    def rawPseudoCount(self, *args) -> List[float]:
        r"""

        computes the pseudoCount (taking priors into account) of the list of variables as a list of floats.


        Parameters
        ----------
        vars: List[intstr]
        	the list of variables

        Returns
        -------
        List[float]
        	the pseudo-count as a list of float

        """
        return _bn.BNLearner_rawPseudoCount(self, *args)

    def nbRows(self) -> int:
        r"""

        Return the number of row in the database


        Returns
        -------
        int
        	the number of rows in the database

        """
        return _bn.BNLearner_nbRows(self)

    def nbCols(self) -> int:
        r"""

        Return the number of columns in the database


        Returns
        -------
        int
        	the number of columns in the database

        """
        return _bn.BNLearner_nbCols(self)

    def domainSize(self, *args) -> int:
        r"""

        Return the domain size of the variable with the given name.

        Parameters
        ----------
        n : str | int
          the name of the id of the variable

        """
        return _bn.BNLearner_domainSize(self, *args)

    def setNumberOfThreads(self, nb: int) -> None:
        r"""

        If the parameter n passed in argument is different from 0, the BNLearner will use n threads during learning, hence overriding pyAgrum default number of threads.
        If, on the contrary, n is equal to 0, the BNLearner will comply with pyAgrum default number of threads.

        Parameters
        ----------
        n : int
        	the number of threads to be used by the BNLearner

        """
        return _bn.BNLearner_setNumberOfThreads(self, nb)

    def getNumberOfThreads(self) -> int:
        r"""

        Return the number of threads used by the BNLearner during structure and parameter learning.

        Returns
        -------
        int
        	the number of threads used by the BNLearner during structure and parameter learning

        """
        return _bn.BNLearner_getNumberOfThreads(self)

    def isGumNumberOfThreadsOverriden(self) -> bool:
        r"""

        Check if the number of threads use by the learner is the default one or not.

        Returns
        -------
        bool
        	True if the number of threads used by the BNLearner has been set.

        """
        return _bn.BNLearner_isGumNumberOfThreadsOverriden(self)

    def chi2(self, *args) -> object:
        r"""

        chi2 computes the chi2 statistic and p-value for two columns, given a list of other columns.


        Parameters
        ----------
        name1: str
        	the name of the first column

        name2 : str
        	the name of the second column

        knowing : List[str]
        	the list of names of conditioning columns

        Returns
        -------
        Tuple[float,float]
        	the chi2 statistic and the associated p-value as a Tuple

        """
        return _bn.BNLearner_chi2(self, *args)

    def G2(self, *args) -> object:
        r"""

        G2 computes the G2 statistic and p-value for two columns, given a list of other columns.


        Parameters
        ----------
        name1: str
        	the name of the first column

        name2 : str
        	the name of the second column

        knowing : List[str]
        	the list of names of conditioning columns

        Returns
        -------
        Tuple[float,float]
        	the G2 statistic and the associated p-value as a Tuple

        """
        return _bn.BNLearner_G2(self, *args)

    def setSliceOrder(self, *args) -> "pyagrum.BNLearner":
        r"""

        Set a partial order on the nodes.

        Parameters
        ----------
        l : list
                a list of sequences (composed of ids of rows or string)

        """
        return _bn.BNLearner_setSliceOrder(self, *args)

    def useK2(self, *args) -> "pyagrum.BNLearner":
        r"""

        Indicate to use the K2 algorithm (which needs a total ordering of the variables).

        Parameters
        ----------
        order : list[int or str]
              sequences of (ids or name)

        """
        return _bn.BNLearner_useK2(self, *args)

    def latentVariables(self) -> object:
        r"""

        Warnings
        --------
        learner must be using MIIC algorithm

        Returns
        -------
        list
        	the list of latent variables

        """
        return _bn.BNLearner_latentVariables(self)

    def state(self) -> object:
        r"""

        Returns a dictionary containing the current state of the BNLearner.

        Returns
        -------
        Dict[str,Any]
            a dictionary containing the current state of the BNLearner.

        """
        return _bn.BNLearner_state(self)

    def setPossibleEdges(self, *args) -> None:
        r"""

        Add a constraint by fixing the set of possible edges.

        Parameters
        ----------
        edges : Set[Tuple[int]]
        	a set of edges as couples of nodeIds.

        """
        return _bn.BNLearner_setPossibleEdges(self, *args)

    def pseudoCount(self,vars):
        """ access to pseudo-count (priors taken into account)

        Parameters
        ----------
        vars : list[str]
          a list of name of vars to add in the pseudo_count

        Returns
        -------
        a Tensor containing this pseudo-counts
        """
        p=pyagrum.base.Tensor()
        lv=list()
        for i in vars:
            if type(i) is str:
                name=i
            else:
                name=self.nameFromId(i)
            p.add(pyagrum.base.RangeVariable(name,name,0,self.domainSize(i)-1))
            lv.append(name)
        p.fillWith(self.rawPseudoCount(lv))
        return p

    def fitParameters(self,bn,take_into_account_score=True):
      """
      fitParameters directly populates the CPTs of the argument using the database and the structure of the BN.

      Parameters
      ----------
      bn : pyagrum.BayesNet
        a BN which will directly have its parameters learned inplace.

      take_into_account_score : bool
    	The dag passed in argument may have been learnt from a structure learning. In this case, if the score used to learn the structure has an implicit prior (like K2 which has a 1-smoothing prior), it is important to also take into account this implicit prior for parameter learning. By default (`take_into_account_score=True`), we will learn parameters by taking into account the prior specified by methods usePriorXXX () + the implicit prior of the score (if any). If `take_into_account_score=False`, we just take into account the prior specified by `usePriorXXX()`.

      """
      if set(self.names())!=bn.names():
        raise Exception("Not the same variable names in the database and in the BN")

      from pyagrum.base import DAG
      d=DAG()
      for n in bn.names():
        d.addNodeWithId(self.idFromName(n))
      for i1,i2 in bn.arcs():
        d.addArc(self.idFromName(bn.variable(i1).name()),self.idFromName(bn.variable(i2).name()))
      tmp=self.learnParameters(d,take_into_account_score)
      for n in tmp.names():
        bn.cpt(n).fillWith(tmp.cpt(n))
      return self

    def learnEssentialGraph(self):
      """
      learn an essential graph from a file

      Returns
      -------
      pyagrum.EssentialGraph
        the learned essential graph
      """
      bn = BayesNet()
      for i in range(len(self.names())):
        bn.add(self.nameFromId(i),2)
      try:
        ge = EssentialGraph(bn,self.learnPDAG()) # for constraint-based methods
      except:
        bn = self.learnBN()
        ge = EssentialGraph(bn)  # for score-based methods

      ge._bn=bn

      return ge


# Register BNLearner in _bn:
_bn.BNLearner_swigregister(BNLearner)

__version__ = '2.0.1'
__license__ = __doc__
__project_url__ = 'https://agrum.org'
__project_name__ = 'pyAgrum'
__project_description__ = __doc__
__project__ = __doc__


def about():
  """
  about() for pyAgrum

  """
  print(f"pyAgrum {__version__}")
  print("(c) 2015-2024 Pierre-Henri Wuillemin, Christophe Gonzales")
  print("""
    This is free software; see the source code for copying conditions.
    There is ABSOLUTELY NO WARRANTY; not even for MERCHANTABILITY or
    FITNESS FOR A PARTICULAR PURPOSE.  For details, see 'pyagrum.warranty'.
    """)


from typing import List
import os.path as ospath
import warnings

def availableBNExts():
  """ Give the list of all formats known by pyAgrum to save a Bayesian network.

  :return: a string which lists all suffixes for supported BN file formats.
  """
  return "bif|dsl|net|bifxml|o3prm|uai|xdsl|pkl"


def loadBN(filename, listeners=None, verbose=False, **opts):
  """load a BN from a file with optional listeners and arguments

  Parameters
  ----------
  filename: str
      the name of the input file
  listeners: List[object]
      list of functions to execute when listening
  verbose: bool
      whether to print or not warning messages
  system: str
      (for O3PRM) name of the system to flatten in a BN
  classpath: List[str]
      (for O3PRM) list of folders containing classes

  Returns
  -------
  pyagrum.BayesNet
      a BN from a file using one of the availableBNExts() suffixes.

  Notes
  ----
      Listeners could be added in order to monitor its loading.

      pkl suffix is used to load a pickled BN. In this case, listeners and options are ignored.

  Examples
  --------
  >>> import pyagrum as gum
  >>>
  >>> # creating listeners
  >>> def foo_listener(progress):
  >>>    if progress==200:
  >>>        print(' BN loaded ')
  >>>        return
  >>>    elif progress==100:
  >>>        car='%'
  >>>    elif progress%10==0:
  >>>        car='#'
  >>>    else:
  >>>        car='.'
  >>>    print(car,end='',flush=True)
  >>>
  >>> def bar_listener(progress):
  >>>    if progress==50:
  >>>        print('50%')
  >>>
  >>> # loadBN with list of listeners
  >>> pyagrum.loadBN('./bn.bif',listeners=[foo_listener,bar_listener])
  >>> # .........#.........#.........#.........#..50%
  >>> # .......#.........#.........#.........#.........#.........% | bn loaded
  """
  bn = BayesNet()

  extension = filename.split('.')[-1].upper()
  if extension == "BIF":
    warns = bn.loadBIF(filename, listeners)
  elif extension == "BIFXML":
    warns = bn.loadBIFXML(filename, listeners)
  elif extension == "DSL":
    warns = bn.loadDSL(filename, listeners)
  elif extension == "XDSL":
    warns = bn.loadXDSL(filename, listeners)
  elif extension == "NET":
    warns = bn.loadNET(filename, listeners)
  elif extension == "O3PRM":
    warns = bn.loadO3PRM(filename, opts.get('system', ''),
                         opts.get('classpath', ''), listeners)
  elif extension == "UAI":
    warns = bn.loadUAI(filename, listeners)
  elif extension == "PKL":
    import pickle
    with open(filename, "rb") as f:
      bn = pickle.load(f)
  else:
    raise InvalidArgument("extension " + filename.split('.')
    [-1] + " unknown. Please use among " + availableBNExts())

  if verbose:
    warnings.warn(warns)

  bn.setProperty("name", bn.propertyWithDefault("name", ospath.splitext(ospath.basename(filename))[0]))
  return bn



def saveBN(bn, filename, allowModificationWhenSaving=None):
  """
  save a BN into a file using the format corresponding to one of the availableWriteBNExts() suffixes.

  Parameters
  ----------
  bn : pyagrum.BayesNet
    the BN to save
  filename : str
    the name of the output file
  allowModificationWhenSaving: bool
      whether syntax errors in the BN should throw a FatalError or can be corrected. Also controlled by `pyagrum.config["BN","allow_modification_when_saving"]`.

  Notes
  ----
      pkl suffix is used to save a BN using pickle. In this case, options are ignored.
  """
  if allowModificationWhenSaving is None:
    allowModificationWhenSaving = pyagrum.base.config.asBool["BN", "allow_modification_when_saving"]

  extension = filename.split('.')[-1].upper()

  if extension == "BIF":
    bn.saveBIF(filename, allowModificationWhenSaving)
  elif extension == "BIFXML":
    bn.saveBIFXML(filename, allowModificationWhenSaving)
  elif extension == "DSL":
    bn.saveDSL(filename, allowModificationWhenSaving)
  elif extension == "XDSL":
    bn.saveXDSL(filename, allowModificationWhenSaving)
  elif extension == "NET":
    bn.saveNET(filename, allowModificationWhenSaving)
  elif extension == "UAI":
    bn.saveUAI(filename, allowModificationWhenSaving)
  elif extension == "O3PRM":
    bn.saveO3PRM(filename, allowModificationWhenSaving)
  elif extension == "PKL":
    import pickle
    with open(filename, "wb") as f:
      pickle.dump(bn, f, pickle.HIGHEST_PROTOCOL)
  else:
    raise InvalidArgument("[pyAgrum] extension " + filename.split('.')
    [-1] + " unknown. Please use among " + availableBNExts())

def fastBN(structure:str, domain="[2]"):
  """
  Create a Bayesian network with a dot-like syntax which specifies:
      - the structure 'a->b->c;b->d<-e;',
      - the type of the variables with different syntax (cf documentation).

  Examples
  --------
  >>> import pyagrum as gum
  >>> bn=pyagrum.fastBN('A->B[1,3]<-C{yes|No}->D[2,4]<-E[1,2.5,3.9]',6)

  Parameters
  ----------
  structure : str
          the string containing the specification
  domain : int or str
          the default domain size (int) or domain specification (str) for variables (default is "[2]"

  Returns
  -------
  pyagrum.BayesNet
          the resulting bayesian network
  """
  return BayesNet.fastPrototype(structure, domain)


def generateSample(bn, n=1, name_out=None, show_progress=False, with_labels=True, random_order=True):
  """
  generate a CSV file of samples from a bn.

  Parameters
  ----------
  bn: pyagrum.BayesNet
    the Bayes Net from which the sample is generated
  n: int
    the number of samples
  name_out: str
    the name for the output csv filename. If name_out is None, a pandas.DataFrame is generated
  show_progress: bool
    if True, show a progress bar. Default is False
  with_labels: bool
    if True, use the labels of the modalities of variables in the csv. If False, use their ids. Default is True
  random_order: bool
    if True, the columns in the csv are randomized sorted. Default is True

  Returns
  -------
  float|Tuple[pandas.DataFrame,float]
    the log2-likelihood of the generated base or if name_out is None, the couple (generated pandas.DataFrame,log2-likelihood)
  """
  genere = BNDatabaseGenerator(bn)
  if show_progress:
    from tqdm import tqdm
    pbar = tqdm(total=100, desc=name_out, bar_format='{desc}: {percentage:3.0f}%|{bar}|', ncols=60)
    listen = PythonDatabaseGeneratorListener(genere)

    def whenStep(x, y):
      pbar.update(1)

    def whenStop(msg):
      pbar.close()

    listen.setWhenProgress(whenStep)
    listen.setWhenStop(whenStop)

  if random_order:
    genere.setRandomVarOrder()
  ll = genere.drawSamples(n)

  if name_out is not None:
    genere.toCSV(name_out, with_labels)

  if show_progress:
    print(f"Log2-Likelihood : {ll}")

  if name_out is not None:
    return ll
  else:
    return genere.to_pandas(with_labels), ll


def randomBN(*, n: int = 5, names: List[str] = None, ratio_arc: float = 1.2, domain_size: int = 2) -> BayesNet:
  """
  Creates a random BN using the (forced) keyword parameters. This function use :class:`pyagrum.BNGenerator` but the random
  variables will be named w.r.t. a topological order.

  Warning
  -------
  Number of nodes given with arg `n`or `names` must be bigger than 4, in order to be consistant

  Examples
  --------
  >>> bn=pyagrum.randomBN()
  >>> bn=pyagrum.randomBN(n=10)
  >>> bn=pyagrum.randomBN(names="ABCDEF")
  >>> bn=pyagrum.randomBN(names=["Asia","Tuberculosis","Smoking"],ratio_arc=1.5,domain_size=3)

  Warnings
  --------
  This function has only keyword parameters (no positional).

  Parameters
  ----------
  n : int
      number of nodes
  names: List[str]
      list of names
  ratio_arc: float
      number of arcs = n * ratio_arc
  domain_size: int
      the domain size for the variables.

  Returns
  -------
    pyagrum.BayesNet
  """
  nbr = n if names is None else len(names)
  if nbr <= 3:
    raise ArgumentError("A BN can not be randomly generated from less than 4 nodes.")

  gen = BNGenerator()
  bn = gen.generate(nbr, int(nbr * ratio_arc), domain_size)

  if names is not None:
# try to find very rare name
    for i in bn.nodes():
      bn.changeVariableName(i, f"__{i}{i}__{i}{i}__")
    for i, nod in enumerate(bn.topologicalOrder()):
      bn.changeVariableName(nod, names[i])

  return bn


def mutilateBN(bn, intervention=None, observation=None):
  """
  Modify the bayesian network bn to reflect the effect of interventions and/or observations on a set of variables.
  Due to the causal nature of interventions, we suppose the given bn to have a causal interpretation.
  Warning: experimental use of evidence definition

  Interventions or observations can be HARD or SOFT.

    Hard interventions or observations:
        1) [0,... 1, 0] -> sum(x) = 1
        3) X : [n] -> with n a value

    Soft interventions or observations:
        1) X : [empty list] -> equiprobability is assumed
        2) X : [x1, ... xn] -> sum(x) = 1
        3) X : [1, ... 1, 0] -> sum(x) >= 1
        4) X : [n1, n2, n3] -> with n_i values that could happen

    X is the name of a variable

  Parameters
  ----------
  bn : pyagrum.pyagrum.BayesNet
    A bayesian network
  intervention : Dict[str,List[str|float|int]]
    set of variables on which we intervene to force the value
  observation : Dict[str,List[str|float|int]]
    set of variables whose value is observed

  Returns
  -------
  inter_bn : new bayesian network reflecting the interventions and observations (pyagrum.pyagrum.BayesNet)
  evidence : dictionary of all evidences for future inferences (dict)
  """
  if intervention is None:
    intervention = dict()

  if observation is None:
    observation = dict()

  inter_bn = BayesNet(bn)

# Check that a variable is not an intervention and an observation
  if len(set(intervention).intersection(set(observation))) > 0:
    raise ValueError('A variable can\'t be an intervention and an observation')

  evidence = dict()  # Track the new distribution to update
  list_hard = dict()  # Track the hard values
  toModify = {"intervention": intervention, "observation": observation}

## Delete relations
  for typeSet in toModify:

# For each variable we wish to modify
    for var in toModify[typeSet]:

# Get the ID and the name
      if var in bn.names():
        var_id = bn.idFromName(var)

      else:
        var_id = var
        var = bn.variable(var_id).name()

# Delete relations from parents for interventions
      if typeSet == "intervention":
        for par in bn.parents(var):
          inter_bn.eraseArc(par, var_id)

# Determine the new distributions
      n = bn.variable(var).domainSize()
      new_dis = toModify[typeSet][var]
      hard = False

      if len(new_dis) == 0:  # soft 1)
        new_dis = [1 / n for _ in range(n)]

      elif str in [type(i) for i in new_dis]:  # hard - soft 3) 4)
        new_dis = [1 if bn.variable(var).labels()[i] == new_dis[0] else 0 for i in range(n)]

        if len(toModify[typeSet][var]) == 1:
          new_val = toModify[typeSet][var][0]
          hard = True

      elif sum(new_dis) == 1 and 1 in new_dis:  # hard 1)
        new_val = bn.variable(var).labels()[new_dis.index(1)]
        hard = True

      evidence[var] = new_dis

# If hard values
      if hard:
# Track the new values
        list_hard[var] = new_val

# Delete relation toward children
        for chi in bn.children(var):
          inter_bn.eraseArc(var_id, chi)

## Update the distributions
  for var in list(evidence):

# Update variable if intervention
    if var in intervention:
      inter_bn.cpt(var).fillWith(evidence[var])

# Update children if hard evidence
    if var in list_hard:
      for chi in bn.children(var):
        new_cpt = bn.cpt(chi)[list_hard]

        inter_bn.cpt(chi)[:] = new_cpt

# If intervention, remove var
      if var in intervention:
        inter_bn.erase(var)
        del evidence[var]

  return (inter_bn, evidence)




